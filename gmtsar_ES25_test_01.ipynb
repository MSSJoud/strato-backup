{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9899dad8",
   "metadata": {},
   "source": [
    "ASF Search and SBAS Stack Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a3e093f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/etc/timezone is deprecated on Debian, and no longer reliable. Ignoring.\n",
      "/mnt/data/tmp/ipykernel_1124523/1628721161.py:10: DeprecationWarning: Parsing dates involving a day of month without a year specified is ambiguious\n",
      "and fails to parse leap day. The default behavior will change in Python 3.15\n",
      "to either always raise an exception or to use a different default year (TBD).\n",
      "To avoid trouble, add a specific year to the input & format.\n",
      "See https://github.com/python/cpython/issues/70647.\n",
      "  opts = asf.ASFSearchOptions(**{\n",
      "/mnt/data/tmp/ipykernel_1124523/1628721161.py:23: DeprecationWarning: Parsing dates involving a day of month without a year specified is ambiguious\n",
      "and fails to parse leap day. The default behavior will change in Python 3.15\n",
      "to either always raise an exception or to use a different default year (TBD).\n",
      "To avoid trouble, add a specific year to the input & format.\n",
      "See https://github.com/python/cpython/issues/70647.\n",
      "  search_results = asf.search(opts=opts)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 24 scenes.\n",
      "Generated 478 SBAS pairs.\n",
      "[<asf_search.Products.S1Product.S1Product object at 0x7fc197b533d0>,\n",
      " <asf_search.Products.S1Product.S1Product object at 0x7fc197b53150>,\n",
      " <asf_search.Products.S1Product.S1Product object at 0x7fc197b52d50>]\n"
     ]
    }
   ],
   "source": [
    "from datetime import date\n",
    "import asf_search as asf\n",
    "from pprint import pprint\n",
    "\n",
    "# Define date range around the Blatten landslide event (28 May 2025)\n",
    "stack_start = date(2025, 4, 15)\n",
    "stack_end = date(2025, 6, 20)\n",
    "\n",
    "# Define ASF search parameters\n",
    "opts = asf.ASFSearchOptions(**{\n",
    "    \"maxResults\": 5000,\n",
    "    \"bbox\": [7.6172, 46.2195, 8.0172, 46.6195],  # Blatten AOI (Switzerland)\n",
    "    \"beamSwath\": [\"IW\"],\n",
    "    \"flightDirection\": \"DESCENDING\",  # Use DESCENDING first, see note below\n",
    "    \"polarization\": [\"VV+VH\", \"VV\"],\n",
    "    \"processingLevel\": [\"SLC\"],\n",
    "    \"start\": stack_start.isoformat(),\n",
    "    \"end\": stack_end.isoformat(),\n",
    "    \"dataset\": [\"SENTINEL-1\"]\n",
    "})\n",
    "\n",
    "# Search SLC scenes from ASF\n",
    "search_results = asf.search(opts=opts)\n",
    "print(f\"Found {len(search_results)} scenes.\")\n",
    "\n",
    "# Create baseline stack (SBAS-compatible) from the most recent scene\n",
    "baseline_results = asf.baseline_search.stack_from_product(search_results[-1])\n",
    "print(f\"Generated {len(baseline_results)} SBAS pairs.\")\n",
    "\n",
    "# Preview first few SBAS pairs\n",
    "pprint(baseline_results[:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a1c0a2",
   "metadata": {},
   "source": [
    "Make some directories "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "30f9071f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEM directory: /mnt/data/gmtsar_test_1/topo\n",
      "RAW SLC directory: /mnt/data/gmtsar_test_1/raw\n",
      "Orbit directory: /mnt/data/gmtsar_test_1/raw\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "\n",
    "# === 1. Define GMTSAR-standard paths ===\n",
    "work_dir = \"/mnt/data/gmtsar_test_1\"\n",
    "download_dir = os.path.join(work_dir, \"raw\")\n",
    "dem_dir = os.path.join(work_dir, \"topo\")\n",
    "orbit_dir = download_dir  # Orbit files go under raw\n",
    "\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "os.makedirs(dem_dir, exist_ok=True)\n",
    "\n",
    "print(f\"DEM directory: {dem_dir}\")\n",
    "print(f\"RAW SLC directory: {download_dir}\")\n",
    "print(f\"Orbit directory: {orbit_dir}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e8a3ba",
   "metadata": {},
   "source": [
    "Make a dataframe of search results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9dce69cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      " ['centerLat', 'centerLon', 'stopTime', 'fileID', 'flightDirection', 'pathNumber', 'processingLevel', 'url', 'startTime', 'sceneName', 'browse', 'platform', 'bytes', 'md5sum', 'frameNumber', 'granuleType', 'orbit', 'polarization', 'processingDate', 'sensor', 'groupID', 'pgeVersion', 'fileName', 'beamModeType', 's3Urls']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sceneName</th>\n",
       "      <th>platform</th>\n",
       "      <th>polarization</th>\n",
       "      <th>beamModeType</th>\n",
       "      <th>orbit</th>\n",
       "      <th>startTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250619T054333_20250619T0544...</td>\n",
       "      <td>Sentinel-1A</td>\n",
       "      <td>VV+VH</td>\n",
       "      <td>IW</td>\n",
       "      <td>59711</td>\n",
       "      <td>2025-06-19T05:43:33Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250614T053536_20250614T0536...</td>\n",
       "      <td>Sentinel-1A</td>\n",
       "      <td>VV+VH</td>\n",
       "      <td>IW</td>\n",
       "      <td>59638</td>\n",
       "      <td>2025-06-14T05:35:36Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250613T054227_20250613T0542...</td>\n",
       "      <td>Sentinel-1C</td>\n",
       "      <td>VV+VH</td>\n",
       "      <td>IW</td>\n",
       "      <td>2760</td>\n",
       "      <td>2025-06-13T05:42:27Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250608T053437_20250608T0535...</td>\n",
       "      <td>Sentinel-1C</td>\n",
       "      <td>VV+VH</td>\n",
       "      <td>IW</td>\n",
       "      <td>2687</td>\n",
       "      <td>2025-06-08T05:34:37Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250608T053413_20250608T0534...</td>\n",
       "      <td>Sentinel-1C</td>\n",
       "      <td>VV+VH</td>\n",
       "      <td>IW</td>\n",
       "      <td>2687</td>\n",
       "      <td>2025-06-08T05:34:13Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sceneName     platform  \\\n",
       "0  S1A_IW_SLC__1SDV_20250619T054333_20250619T0544...  Sentinel-1A   \n",
       "1  S1A_IW_SLC__1SDV_20250614T053536_20250614T0536...  Sentinel-1A   \n",
       "2  S1C_IW_SLC__1SDV_20250613T054227_20250613T0542...  Sentinel-1C   \n",
       "3  S1C_IW_SLC__1SDV_20250608T053437_20250608T0535...  Sentinel-1C   \n",
       "4  S1C_IW_SLC__1SDV_20250608T053413_20250608T0534...  Sentinel-1C   \n",
       "\n",
       "  polarization beamModeType  orbit             startTime  \n",
       "0        VV+VH           IW  59711  2025-06-19T05:43:33Z  \n",
       "1        VV+VH           IW  59638  2025-06-14T05:35:36Z  \n",
       "2        VV+VH           IW   2760  2025-06-13T05:42:27Z  \n",
       "3        VV+VH           IW   2687  2025-06-08T05:34:37Z  \n",
       "4        VV+VH           IW   2687  2025-06-08T05:34:13Z  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert to DataFrame\n",
    "search_df = pd.DataFrame([result.properties for result in search_results])\n",
    "\n",
    "# Check available columns\n",
    "print(\"Available columns:\\n\", search_df.columns.tolist())\n",
    "\n",
    "# Preview first few rows\n",
    "search_df[['sceneName', 'platform', 'polarization','beamModeType','orbit', 'startTime']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "155fbd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_df.to_csv(os.path.join(work_dir, \"search_df.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "95a673d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search returned 24 scenes.\n",
      "Date range: 2025-04-15T05:35:37Z to 2025-06-19T05:43:33Z\n"
     ]
    }
   ],
   "source": [
    "print(f\"Search returned {len(search_df)} scenes.\")\n",
    "print(\"Date range:\", search_df['startTime'].min(), \"to\", search_df['startTime'].max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed64ce66",
   "metadata": {},
   "source": [
    "Extract a stack product in my time span "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "218f2295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      " ['centerLat', 'centerLon', 'stopTime', 'fileID', 'flightDirection', 'pathNumber', 'processingLevel', 'url', 'startTime', 'sceneName', 'browse', 'platform', 'bytes', 'md5sum', 'frameNumber', 'granuleType', 'orbit', 'polarization', 'processingDate', 'sensor', 'groupID', 'pgeVersion', 'fileName', 'beamModeType', 's3Urls', 'temporalBaseline', 'perpendicularBaseline', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sceneName</th>\n",
       "      <th>startTime</th>\n",
       "      <th>stopTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>2025-04-15T05:35:37Z</td>\n",
       "      <td>2025-04-15T05:36:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...</td>\n",
       "      <td>2025-04-27T05:35:38Z</td>\n",
       "      <td>2025-04-27T05:36:05Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...</td>\n",
       "      <td>2025-05-03T05:34:34Z</td>\n",
       "      <td>2025-05-03T05:35:01Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...</td>\n",
       "      <td>2025-05-09T05:35:37Z</td>\n",
       "      <td>2025-05-09T05:36:04Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...</td>\n",
       "      <td>2025-05-15T05:34:35Z</td>\n",
       "      <td>2025-05-15T05:35:02Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sceneName             startTime  \\\n",
       "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...  2025-04-15T05:35:37Z   \n",
       "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...  2025-04-27T05:35:38Z   \n",
       "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...  2025-05-03T05:34:34Z   \n",
       "3  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...  2025-05-09T05:35:37Z   \n",
       "4  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...  2025-05-15T05:34:35Z   \n",
       "\n",
       "               stopTime  \n",
       "0  2025-04-15T05:36:04Z  \n",
       "1  2025-04-27T05:36:05Z  \n",
       "2  2025-05-03T05:35:01Z  \n",
       "3  2025-05-09T05:36:04Z  \n",
       "4  2025-05-15T05:35:02Z  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dateutil.parser import parse as parse_date\n",
    "import pandas as pd\n",
    "# Extract properties and geometry from baseline results\n",
    "list(scene.properties.values() for scene in baseline_results[:3])\n",
    "# Create a DataFrame from the baseline results\n",
    "stack = pd.DataFrame([\n",
    "    list(scene.properties.values()) + [scene.geometry]\n",
    "    for scene in baseline_results\n",
    "    if stack_start <= parse_date(scene.properties['startTime']) <= stack_end\n",
    "], columns=list(baseline_results[0].properties.keys()) + ['geometry'])\n",
    "# Show available columns\n",
    "print(\"Available columns:\\n\", stack.columns.tolist())\n",
    "\n",
    "# Preview the first few rows\n",
    "stack[['sceneName', 'startTime', 'stopTime']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "dee47c08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      " ['centerLat', 'centerLon', 'stopTime', 'fileID', 'flightDirection', 'pathNumber', 'processingLevel', 'url', 'startTime', 'sceneName', 'browse', 'platform', 'bytes', 'md5sum', 'frameNumber', 'granuleType', 'orbit', 'polarization', 'processingDate', 'sensor', 'groupID', 'pgeVersion', 'fileName', 'beamModeType', 's3Urls', 'temporalBaseline', 'perpendicularBaseline', 'geometry']\n",
      "--- Geometry 1 ---\n",
      "{'coordinates': [[[10.252147, 46.595284], [6.912548, 46.993725], [6.553195, 45.376583], [9.79403, 44.978661], [10.252147, 46.595284]]], 'type': 'Polygon'}\n",
      "--- Geometry 2 ---\n",
      "{'coordinates': [[[10.248555, 46.595936], [6.908627, 46.99435], [6.549314, 45.377087], [9.790461, 44.979187], [10.248555, 46.595936]]], 'type': 'Polygon'}\n",
      "--- Geometry 3 ---\n",
      "{'coordinates': [[[10.086966, 45.932964], [6.773118, 46.333443], [6.416841, 44.716366], [9.634801, 44.316227], [10.086966, 45.932964]]], 'type': 'Polygon'}\n",
      "--- Geometry 4 ---\n",
      "{'coordinates': [[[10.249989, 46.59584], [6.910178, 46.994221], [6.550885, 45.376953], [9.791917, 44.979088], [10.249989, 46.59584]]], 'type': 'Polygon'}\n",
      "--- Geometry 5 ---\n",
      "{'coordinates': [[[10.086464, 45.933083], [6.772568, 46.333534], [6.416298, 44.716331], [9.634297, 44.316219], [10.086464, 45.933083]]], 'type': 'Polygon'}\n",
      "--- Geometry 6 ---\n",
      "{'coordinates': [[[10.251045, 46.595608], [6.911162, 46.994015], [6.551862, 45.376755], [9.792971, 44.978863], [10.251045, 46.595608]]], 'type': 'Polygon'}\n",
      "--- Geometry 7 ---\n",
      "{'coordinates': [[[10.081774, 45.932953], [6.767879, 46.333389], [6.411645, 44.716309], [9.629649, 44.316208], [10.081774, 45.932953]]], 'type': 'Polygon'}\n",
      "--- Geometry 8 ---\n",
      "{'coordinates': [[[10.249871, 46.596004], [6.909928, 46.994373], [6.550663, 45.377106], [9.791823, 44.979252], [10.249871, 46.596004]]], 'type': 'Polygon'}\n",
      "--- Geometry 9 ---\n",
      "{'coordinates': [[[10.082045, 45.932968], [6.768129, 46.333416], [6.411886, 44.716335], [9.62991, 44.316223], [10.082045, 45.932968]]], 'type': 'Polygon'}\n",
      "--- Geometry 10 ---\n",
      "{'coordinates': [[[10.24911, 46.595909], [6.909115, 46.994225], [6.549939, 45.377079], [9.791157, 44.979275], [10.24911, 46.595909]]], 'type': 'Polygon'}\n"
     ]
    }
   ],
   "source": [
    "# Check available columns\n",
    "print(\"Available columns:\\n\", stack.columns.tolist())\n",
    "\n",
    "# Loop through and print geometry WKT or coordinates\n",
    "for i, geom in enumerate(stack['geometry']):\n",
    "    print(f\"--- Geometry {i+1} ---\")\n",
    "    print(geom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c0bb440a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Geometry 1 ---\n",
      "Lon: 10.252147, Lat: 46.595284\n",
      "Lon: 6.912548, Lat: 46.993725\n",
      "Lon: 6.553195, Lat: 45.376583\n",
      "Lon: 9.79403, Lat: 44.978661\n",
      "Lon: 10.252147, Lat: 46.595284\n",
      "--- Geometry 2 ---\n",
      "Lon: 10.248555, Lat: 46.595936\n",
      "Lon: 6.908627, Lat: 46.99435\n",
      "Lon: 6.549314, Lat: 45.377087\n",
      "Lon: 9.790461, Lat: 44.979187\n",
      "Lon: 10.248555, Lat: 46.595936\n",
      "--- Geometry 3 ---\n",
      "Lon: 10.086966, Lat: 45.932964\n",
      "Lon: 6.773118, Lat: 46.333443\n",
      "Lon: 6.416841, Lat: 44.716366\n",
      "Lon: 9.634801, Lat: 44.316227\n",
      "Lon: 10.086966, Lat: 45.932964\n",
      "--- Geometry 4 ---\n",
      "Lon: 10.249989, Lat: 46.59584\n",
      "Lon: 6.910178, Lat: 46.994221\n",
      "Lon: 6.550885, Lat: 45.376953\n",
      "Lon: 9.791917, Lat: 44.979088\n",
      "Lon: 10.249989, Lat: 46.59584\n",
      "--- Geometry 5 ---\n",
      "Lon: 10.086464, Lat: 45.933083\n",
      "Lon: 6.772568, Lat: 46.333534\n",
      "Lon: 6.416298, Lat: 44.716331\n",
      "Lon: 9.634297, Lat: 44.316219\n",
      "Lon: 10.086464, Lat: 45.933083\n",
      "--- Geometry 6 ---\n",
      "Lon: 10.251045, Lat: 46.595608\n",
      "Lon: 6.911162, Lat: 46.994015\n",
      "Lon: 6.551862, Lat: 45.376755\n",
      "Lon: 9.792971, Lat: 44.978863\n",
      "Lon: 10.251045, Lat: 46.595608\n",
      "--- Geometry 7 ---\n",
      "Lon: 10.081774, Lat: 45.932953\n",
      "Lon: 6.767879, Lat: 46.333389\n",
      "Lon: 6.411645, Lat: 44.716309\n",
      "Lon: 9.629649, Lat: 44.316208\n",
      "Lon: 10.081774, Lat: 45.932953\n",
      "--- Geometry 8 ---\n",
      "Lon: 10.249871, Lat: 46.596004\n",
      "Lon: 6.909928, Lat: 46.994373\n",
      "Lon: 6.550663, Lat: 45.377106\n",
      "Lon: 9.791823, Lat: 44.979252\n",
      "Lon: 10.249871, Lat: 46.596004\n",
      "--- Geometry 9 ---\n",
      "Lon: 10.082045, Lat: 45.932968\n",
      "Lon: 6.768129, Lat: 46.333416\n",
      "Lon: 6.411886, Lat: 44.716335\n",
      "Lon: 9.62991, Lat: 44.316223\n",
      "Lon: 10.082045, Lat: 45.932968\n",
      "--- Geometry 10 ---\n",
      "Lon: 10.24911, Lat: 46.595909\n",
      "Lon: 6.909115, Lat: 46.994225\n",
      "Lon: 6.549939, Lat: 45.377079\n",
      "Lon: 9.791157, Lat: 44.979275\n",
      "Lon: 10.24911, Lat: 46.595909\n",
      "\n",
      "[Overall Bounding Box for All Geometries]\n",
      "W: 6.411645, E: 10.252147, S: 44.316208, N: 46.994373\n"
     ]
    }
   ],
   "source": [
    "# Initialize overall bounds\n",
    "min_lon, min_lat = float('inf'), float('inf')\n",
    "max_lon, max_lat = float('-inf'), float('-inf')\n",
    "\n",
    "# Loop through geometries and extract bounds\n",
    "for i, geom in enumerate(stack['geometry']):\n",
    "    coords = geom['coordinates'][0]  # Assuming Polygon, not MultiPolygon\n",
    "    print(f\"--- Geometry {i+1} ---\")\n",
    "    for lon, lat in coords:\n",
    "        print(f\"Lon: {lon}, Lat: {lat}\")\n",
    "        # Update global bounds\n",
    "        min_lon = min(min_lon, lon)\n",
    "        max_lon = max(max_lon, lon)\n",
    "        min_lat = min(min_lat, lat)\n",
    "        max_lat = max(max_lat, lat)\n",
    "\n",
    "# Print overall WESN bounds\n",
    "print(\"\\n[Overall Bounding Box for All Geometries]\")\n",
    "print(f\"W: {min_lon}, E: {max_lon}, S: {min_lat}, N: {max_lat}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687c011",
   "metadata": {},
   "source": [
    "Save a pkl of the serach object in the current pwd and in the work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7c7ec0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the object\n",
    "with open(\"search_results.pkl\", \"wb\") as f:\n",
    "    pickle.dump(search_results, f)\n",
    "with open(os.path.join(work_dir, \"search_results.pkl\"), \"wb\") as f:\n",
    "    pickle.dump(search_results, f)\n",
    "# Load it later\n",
    "with open(\"search_results.pkl\", \"rb\") as f:\n",
    "    search_results = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb8ed63",
   "metadata": {},
   "source": [
    "Save a csv of the stack "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "48c7470d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack.to_csv(os.path.join(work_dir, \"sbas_stack_metadata.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b9b712",
   "metadata": {},
   "source": [
    "Printout the bbox based on teh geometries from stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6e1bf8a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clean Bounding Box: [6.4116, 44.3162, 10.2521, 46.9944]\n",
      "Date Range: 2025-04-15 to 2025-06-14\n"
     ]
    }
   ],
   "source": [
    "from shapely.geometry import shape\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Convert geometries to shapely objects\n",
    "geometries = [shape(g) for g in stack[\"geometry\"]]\n",
    "all_coords = np.vstack([np.array(geom.exterior.coords) for geom in geometries])\n",
    "\n",
    "# Compute bounding box\n",
    "min_lon, min_lat = map(float, np.min(all_coords, axis=0))\n",
    "max_lon, max_lat = map(float, np.max(all_coords, axis=0))\n",
    "\n",
    "bbox = [round(min_lon, 4), round(min_lat, 4), round(max_lon, 4), round(max_lat, 4)]\n",
    "\n",
    "# Date range\n",
    "start_dates = pd.to_datetime(stack[\"startTime\"])\n",
    "min_date = start_dates.min().date()\n",
    "max_date = start_dates.max().date()\n",
    "\n",
    "# Output\n",
    "print(\"Clean Bounding Box:\", bbox)\n",
    "print(\"Date Range:\", min_date, \"to\", max_date)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e289ce",
   "metadata": {},
   "source": [
    "Create all possible interferometric pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0083ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pairs: 45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>master</th>\n",
       "      <th>slave</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>S1A_IW_SLC__1SDV_20250521T053537_20250521T0536...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              master  \\\n",
       "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
       "1  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
       "2  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
       "3  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
       "4  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
       "\n",
       "                                               slave  \n",
       "0  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...  \n",
       "1  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...  \n",
       "2  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...  \n",
       "3  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...  \n",
       "4  S1A_IW_SLC__1SDV_20250521T053537_20250521T0536...  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "# Create all possible unique interferometric pairs (master, slave)\n",
    "pairs = list(combinations(stack.sort_values('startTime')['sceneName'], 2))\n",
    "\n",
    "# Or as DataFrame for clarity\n",
    "pairs_df = pd.DataFrame(pairs, columns=['master', 'slave'])\n",
    "\n",
    "print(\"Total pairs:\", len(pairs_df))\n",
    "pairs_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157d4b17",
   "metadata": {},
   "source": [
    "Define time range and InSAR processing parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a34d83f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "# Your known date range\n",
    "start_date = '2025-04-15'\n",
    "end_date = '2025-06-19'\n",
    "\n",
    "# Parse to datetime and extract year & seasonal window\n",
    "stack_start = parse_date(start_date + ' 00:00:00Z')\n",
    "stack_end = parse_date(end_date + ' 00:00:00Z')\n",
    "\n",
    "year_start = stack_start.year\n",
    "year_end = stack_end.year\n",
    "season_period = [start_date[5:], end_date[5:]]\n",
    "\n",
    "# Processing parameters\n",
    "max_temporal_baseline = 36              # Maximum days between pairs\n",
    "interannual_baseline_max = 380          # Not applicable here, but defined\n",
    "interannual_baseline_min = 350\n",
    "look_nums = '20x4'                      # Range x Azimuth multilook factors\n",
    "phase_filter_para = 0.8                 # Exponent for adaptive phase filtering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82430017",
   "metadata": {},
   "source": [
    "Filter stack for seasonal subset by year\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b39251bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil.parser import parse as parse_date\n",
    "\n",
    "stack['startTime'] = stack['startTime'].apply(parse_date)\n",
    "stack['startTime'] = stack['startTime'].dt.tz_localize(None)  # remove timezone if needed\n",
    "\n",
    "\n",
    "stack_season = pd.DataFrame()\n",
    "for year_index in range(int(year_start), int(year_end) + 1):\n",
    "    season_start = parse_date(f'{str(year_index)}-{season_period[0]} 00:00:00Z').replace(tzinfo=None)\n",
    "    season_end = parse_date(f'{str(year_index)}-{season_period[1]} 00:00:00Z').replace(tzinfo=None)\n",
    "    stack_season = pd.concat([\n",
    "        stack_season,\n",
    "        stack.loc[(season_start <= stack.startTime) & (stack.startTime <= season_end)]\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3c64ee59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns:\n",
      " ['centerLat', 'centerLon', 'stopTime', 'fileID', 'flightDirection', 'pathNumber', 'processingLevel', 'url', 'startTime', 'sceneName', 'browse', 'platform', 'bytes', 'md5sum', 'frameNumber', 'granuleType', 'orbit', 'polarization', 'processingDate', 'sensor', 'groupID', 'pgeVersion', 'fileName', 'beamModeType', 's3Urls', 'temporalBaseline', 'perpendicularBaseline', 'geometry']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sceneName</th>\n",
       "      <th>startTime</th>\n",
       "      <th>stopTime</th>\n",
       "      <th>temporalBaseline</th>\n",
       "      <th>perpendicularBaseline</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...</td>\n",
       "      <td>2025-04-15 05:35:37</td>\n",
       "      <td>2025-04-15T05:36:04Z</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'coordinates': [[[10.252147, 46.595284], [6.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...</td>\n",
       "      <td>2025-04-27 05:35:38</td>\n",
       "      <td>2025-04-27T05:36:05Z</td>\n",
       "      <td>12</td>\n",
       "      <td>303</td>\n",
       "      <td>{'coordinates': [[[10.248555, 46.595936], [6.9...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...</td>\n",
       "      <td>2025-05-03 05:34:34</td>\n",
       "      <td>2025-05-03T05:35:01Z</td>\n",
       "      <td>18</td>\n",
       "      <td>-344</td>\n",
       "      <td>{'coordinates': [[[10.086966, 45.932964], [6.7...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...</td>\n",
       "      <td>2025-05-09 05:35:37</td>\n",
       "      <td>2025-05-09T05:36:04Z</td>\n",
       "      <td>24</td>\n",
       "      <td>193</td>\n",
       "      <td>{'coordinates': [[[10.249989, 46.59584], [6.91...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...</td>\n",
       "      <td>2025-05-15 05:34:35</td>\n",
       "      <td>2025-05-15T05:35:02Z</td>\n",
       "      <td>30</td>\n",
       "      <td>-302</td>\n",
       "      <td>{'coordinates': [[[10.086464, 45.933083], [6.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sceneName           startTime  \\\n",
       "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536... 2025-04-15 05:35:37   \n",
       "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536... 2025-04-27 05:35:38   \n",
       "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535... 2025-05-03 05:34:34   \n",
       "3  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536... 2025-05-09 05:35:37   \n",
       "4  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535... 2025-05-15 05:34:35   \n",
       "\n",
       "               stopTime  temporalBaseline  perpendicularBaseline  \\\n",
       "0  2025-04-15T05:36:04Z                 0                      0   \n",
       "1  2025-04-27T05:36:05Z                12                    303   \n",
       "2  2025-05-03T05:35:01Z                18                   -344   \n",
       "3  2025-05-09T05:36:04Z                24                    193   \n",
       "4  2025-05-15T05:35:02Z                30                   -302   \n",
       "\n",
       "                                            geometry  \n",
       "0  {'coordinates': [[[10.252147, 46.595284], [6.9...  \n",
       "1  {'coordinates': [[[10.248555, 46.595936], [6.9...  \n",
       "2  {'coordinates': [[[10.086966, 45.932964], [6.7...  \n",
       "3  {'coordinates': [[[10.249989, 46.59584], [6.91...  \n",
       "4  {'coordinates': [[[10.086464, 45.933083], [6.7...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Available columns:\\n\", stack_season.columns.tolist())\n",
    "\n",
    "# Preview the first few rows\n",
    "stack_season[['sceneName', 'startTime', 'stopTime','temporalBaseline', 'perpendicularBaseline','geometry']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1e606f11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of SAR scenes in stack_season: 10\n",
      "   centerLat  centerLon              stopTime  \\\n",
      "0    45.9979     8.3829  2025-04-15T05:36:04Z   \n",
      "1    45.9985     8.3792  2025-04-27T05:36:05Z   \n",
      "2    45.3364     8.2328  2025-05-03T05:35:01Z   \n",
      "3    45.9984     8.3807  2025-05-09T05:36:04Z   \n",
      "4    45.3365     8.2323  2025-05-15T05:35:02Z   \n",
      "\n",
      "                                              fileID flightDirection  \\\n",
      "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...      DESCENDING   \n",
      "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...      DESCENDING   \n",
      "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...      DESCENDING   \n",
      "3  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...      DESCENDING   \n",
      "4  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...      DESCENDING   \n",
      "\n",
      "   pathNumber processingLevel  \\\n",
      "0          66             SLC   \n",
      "1          66             SLC   \n",
      "2          66             SLC   \n",
      "3          66             SLC   \n",
      "4          66             SLC   \n",
      "\n",
      "                                                 url           startTime  \\\n",
      "0  https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_... 2025-04-15 05:35:37   \n",
      "1  https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_... 2025-04-27 05:35:38   \n",
      "2  https://datapool.asf.alaska.edu/SLC/SC/S1C_IW_... 2025-05-03 05:34:34   \n",
      "3  https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_... 2025-05-09 05:35:37   \n",
      "4  https://datapool.asf.alaska.edu/SLC/SC/S1C_IW_... 2025-05-15 05:34:35   \n",
      "\n",
      "                                           sceneName  ...  \\\n",
      "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...  ...   \n",
      "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...  ...   \n",
      "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...  ...   \n",
      "3  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...  ...   \n",
      "4  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...  ...   \n",
      "\n",
      "         processingDate sensor                        groupID pgeVersion  \\\n",
      "0  2025-04-15T05:35:37Z  C-SAR  S1A_IWDV_0438_0445_058763_066     003.91   \n",
      "1  2025-04-27T05:35:38Z  C-SAR  S1A_IWDV_0438_0445_058938_066     003.91   \n",
      "2  2025-05-03T05:34:34Z  C-SAR  S1C_IWDV_0441_0447_002162_066     003.91   \n",
      "3  2025-05-09T05:35:37Z  C-SAR  S1A_IWDV_0438_0445_059113_066     003.91   \n",
      "4  2025-05-15T05:34:35Z  C-SAR  S1C_IWDV_0441_0447_002337_066     003.91   \n",
      "\n",
      "                                            fileName beamModeType  \\\n",
      "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...           IW   \n",
      "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...           IW   \n",
      "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...           IW   \n",
      "3  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...           IW   \n",
      "4  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...           IW   \n",
      "\n",
      "                                              s3Urls temporalBaseline  \\\n",
      "0  [s3://asf-ngap2w-p-s1-slc-7b420b89/S1A_IW_SLC_...                0   \n",
      "1  [s3://asf-ngap2w-p-s1-slc-7b420b89/S1A_IW_SLC_...               12   \n",
      "2  [s3://asf-ngap2w-p-s1-slc-7b420b89/S1C_IW_SLC_...               18   \n",
      "3  [s3://asf-ngap2w-p-s1-slc-7b420b89/S1A_IW_SLC_...               24   \n",
      "4  [s3://asf-ngap2w-p-s1-slc-7b420b89/S1C_IW_SLC_...               30   \n",
      "\n",
      "  perpendicularBaseline                                           geometry  \n",
      "0                     0  {'coordinates': [[[10.252147, 46.595284], [6.9...  \n",
      "1                   303  {'coordinates': [[[10.248555, 46.595936], [6.9...  \n",
      "2                  -344  {'coordinates': [[[10.086966, 45.932964], [6.7...  \n",
      "3                   193  {'coordinates': [[[10.249989, 46.59584], [6.91...  \n",
      "4                  -302  {'coordinates': [[[10.086464, 45.933083], [6.7...  \n",
      "\n",
      "[5 rows x 28 columns]\n",
      "                                           sceneName           startTime  \\\n",
      "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536... 2025-04-15 05:35:37   \n",
      "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536... 2025-04-27 05:35:38   \n",
      "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535... 2025-05-03 05:34:34   \n",
      "3  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536... 2025-05-09 05:35:37   \n",
      "4  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535... 2025-05-15 05:34:35   \n",
      "5  S1A_IW_SLC__1SDV_20250521T053537_20250521T0536... 2025-05-21 05:35:37   \n",
      "6  S1C_IW_SLC__1SDV_20250527T053437_20250527T0535... 2025-05-27 05:34:37   \n",
      "7  S1A_IW_SLC__1SDV_20250602T053537_20250602T0536... 2025-06-02 05:35:37   \n",
      "8  S1C_IW_SLC__1SDV_20250608T053437_20250608T0535... 2025-06-08 05:34:37   \n",
      "9  S1A_IW_SLC__1SDV_20250614T053536_20250614T0536... 2025-06-14 05:35:36   \n",
      "\n",
      "   temporalBaseline  \n",
      "0                 0  \n",
      "1                12  \n",
      "2                18  \n",
      "3                24  \n",
      "4                30  \n",
      "5                36  \n",
      "6                42  \n",
      "7                48  \n",
      "8                54  \n",
      "9                60  \n",
      "        centerLat  centerLon              stopTime  \\\n",
      "count   10.000000  10.000000                    10   \n",
      "unique        NaN        NaN                    10   \n",
      "top           NaN        NaN  2025-04-15T05:36:04Z   \n",
      "freq          NaN        NaN                     1   \n",
      "mean    45.733570   8.320520                   NaN   \n",
      "min     45.336400   8.227600                   NaN   \n",
      "25%     45.336425   8.232425                   NaN   \n",
      "50%     45.998050   8.379450                   NaN   \n",
      "75%     45.998475   8.380650                   NaN   \n",
      "max     45.998500   8.382900                   NaN   \n",
      "std      0.341808   0.077823                   NaN   \n",
      "\n",
      "                                                   fileID flightDirection  \\\n",
      "count                                                  10              10   \n",
      "unique                                                 10               1   \n",
      "top     S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...      DESCENDING   \n",
      "freq                                                    1              10   \n",
      "mean                                                  NaN             NaN   \n",
      "min                                                   NaN             NaN   \n",
      "25%                                                   NaN             NaN   \n",
      "50%                                                   NaN             NaN   \n",
      "75%                                                   NaN             NaN   \n",
      "max                                                   NaN             NaN   \n",
      "std                                                   NaN             NaN   \n",
      "\n",
      "        pathNumber processingLevel  \\\n",
      "count         10.0              10   \n",
      "unique         NaN               1   \n",
      "top            NaN             SLC   \n",
      "freq           NaN              10   \n",
      "mean          66.0             NaN   \n",
      "min           66.0             NaN   \n",
      "25%           66.0             NaN   \n",
      "50%           66.0             NaN   \n",
      "75%           66.0             NaN   \n",
      "max           66.0             NaN   \n",
      "std            0.0             NaN   \n",
      "\n",
      "                                                      url  \\\n",
      "count                                                  10   \n",
      "unique                                                 10   \n",
      "top     https://datapool.asf.alaska.edu/SLC/SA/S1A_IW_...   \n",
      "freq                                                    1   \n",
      "mean                                                  NaN   \n",
      "min                                                   NaN   \n",
      "25%                                                   NaN   \n",
      "50%                                                   NaN   \n",
      "75%                                                   NaN   \n",
      "max                                                   NaN   \n",
      "std                                                   NaN   \n",
      "\n",
      "                            startTime  \\\n",
      "count                              10   \n",
      "unique                            NaN   \n",
      "top                               NaN   \n",
      "freq                              NaN   \n",
      "mean       2025-05-17 15:11:12.500000   \n",
      "min               2025-04-15 05:35:37   \n",
      "25%     2025-05-04 17:34:49.750000128   \n",
      "50%               2025-05-18 05:35:06   \n",
      "75%               2025-05-31 17:35:22   \n",
      "max               2025-06-14 05:35:36   \n",
      "std                               NaN   \n",
      "\n",
      "                                                sceneName  ...  \\\n",
      "count                                                  10  ...   \n",
      "unique                                                 10  ...   \n",
      "top     S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...  ...   \n",
      "freq                                                    1  ...   \n",
      "mean                                                  NaN  ...   \n",
      "min                                                   NaN  ...   \n",
      "25%                                                   NaN  ...   \n",
      "50%                                                   NaN  ...   \n",
      "75%                                                   NaN  ...   \n",
      "max                                                   NaN  ...   \n",
      "std                                                   NaN  ...   \n",
      "\n",
      "              processingDate sensor                        groupID pgeVersion  \\\n",
      "count                     10     10                             10         10   \n",
      "unique                    10      1                             10          2   \n",
      "top     2025-04-15T05:35:37Z  C-SAR  S1A_IWDV_0438_0445_058763_066     003.91   \n",
      "freq                       1     10                              1          9   \n",
      "mean                     NaN    NaN                            NaN        NaN   \n",
      "min                      NaN    NaN                            NaN        NaN   \n",
      "25%                      NaN    NaN                            NaN        NaN   \n",
      "50%                      NaN    NaN                            NaN        NaN   \n",
      "75%                      NaN    NaN                            NaN        NaN   \n",
      "max                      NaN    NaN                            NaN        NaN   \n",
      "std                      NaN    NaN                            NaN        NaN   \n",
      "\n",
      "                                                 fileName beamModeType  \\\n",
      "count                                                  10           10   \n",
      "unique                                                 10            1   \n",
      "top     S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...           IW   \n",
      "freq                                                    1           10   \n",
      "mean                                                  NaN          NaN   \n",
      "min                                                   NaN          NaN   \n",
      "25%                                                   NaN          NaN   \n",
      "50%                                                   NaN          NaN   \n",
      "75%                                                   NaN          NaN   \n",
      "max                                                   NaN          NaN   \n",
      "std                                                   NaN          NaN   \n",
      "\n",
      "                                                   s3Urls temporalBaseline  \\\n",
      "count                                                  10        10.000000   \n",
      "unique                                                 10              NaN   \n",
      "top     [s3://asf-ngap2w-p-s1-slc-7b420b89/S1A_IW_SLC_...              NaN   \n",
      "freq                                                    1              NaN   \n",
      "mean                                                  NaN        32.400000   \n",
      "min                                                   NaN         0.000000   \n",
      "25%                                                   NaN        19.500000   \n",
      "50%                                                   NaN        33.000000   \n",
      "75%                                                   NaN        46.500000   \n",
      "max                                                   NaN        60.000000   \n",
      "std                                                   NaN        19.224984   \n",
      "\n",
      "       perpendicularBaseline  \\\n",
      "count               10.00000   \n",
      "unique                   NaN   \n",
      "top                      NaN   \n",
      "freq                     NaN   \n",
      "mean                50.30000   \n",
      "min               -344.00000   \n",
      "25%                  2.50000   \n",
      "50%                 81.50000   \n",
      "75%                205.75000   \n",
      "max                303.00000   \n",
      "std                223.73747   \n",
      "\n",
      "                                                 geometry  \n",
      "count                                                  10  \n",
      "unique                                                 10  \n",
      "top     {'coordinates': [[[10.252147, 46.595284], [6.9...  \n",
      "freq                                                    1  \n",
      "mean                                                  NaN  \n",
      "min                                                   NaN  \n",
      "25%                                                   NaN  \n",
      "50%                                                   NaN  \n",
      "75%                                                   NaN  \n",
      "max                                                   NaN  \n",
      "std                                                   NaN  \n",
      "\n",
      "[11 rows x 28 columns]\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 10 entries, 0 to 9\n",
      "Data columns (total 28 columns):\n",
      " #   Column                 Non-Null Count  Dtype         \n",
      "---  ------                 --------------  -----         \n",
      " 0   centerLat              10 non-null     float64       \n",
      " 1   centerLon              10 non-null     float64       \n",
      " 2   stopTime               10 non-null     object        \n",
      " 3   fileID                 10 non-null     object        \n",
      " 4   flightDirection        10 non-null     object        \n",
      " 5   pathNumber             10 non-null     int64         \n",
      " 6   processingLevel        10 non-null     object        \n",
      " 7   url                    10 non-null     object        \n",
      " 8   startTime              10 non-null     datetime64[ns]\n",
      " 9   sceneName              10 non-null     object        \n",
      " 10  browse                 0 non-null      object        \n",
      " 11  platform               10 non-null     object        \n",
      " 12  bytes                  10 non-null     int64         \n",
      " 13  md5sum                 10 non-null     object        \n",
      " 14  frameNumber            10 non-null     int64         \n",
      " 15  granuleType            10 non-null     object        \n",
      " 16  orbit                  10 non-null     int64         \n",
      " 17  polarization           10 non-null     object        \n",
      " 18  processingDate         10 non-null     object        \n",
      " 19  sensor                 10 non-null     object        \n",
      " 20  groupID                10 non-null     object        \n",
      " 21  pgeVersion             10 non-null     object        \n",
      " 22  fileName               10 non-null     object        \n",
      " 23  beamModeType           10 non-null     object        \n",
      " 24  s3Urls                 10 non-null     object        \n",
      " 25  temporalBaseline       10 non-null     int64         \n",
      " 26  perpendicularBaseline  10 non-null     int64         \n",
      " 27  geometry               10 non-null     object        \n",
      "dtypes: datetime64[ns](1), float64(2), int64(6), object(19)\n",
      "memory usage: 2.3+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of SAR scenes in stack_season:\", len(stack_season))\n",
    "print(stack_season.head())  # default is 5 rows\n",
    "print(stack_season[['sceneName', 'startTime', 'temporalBaseline']].head(10))\n",
    "print(stack_season.describe(include='all'))\n",
    "print(stack_season.info())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2007dbd",
   "metadata": {},
   "source": [
    "Construct SBAS interferometric pairs - seasonal + interannual "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ea20a89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The seasonal interferometric pairs are (reference-secondary): \n",
      "20250608 20250614\n",
      "20250602 20250608\n",
      "20250602 20250614\n",
      "20250527 20250602\n",
      "20250527 20250608\n",
      "20250527 20250614\n",
      "20250521 20250527\n",
      "20250521 20250602\n",
      "20250521 20250608\n",
      "20250521 20250614\n",
      "20250515 20250521\n",
      "20250515 20250527\n",
      "20250515 20250602\n",
      "20250515 20250608\n",
      "20250515 20250614\n",
      "20250509 20250515\n",
      "20250509 20250521\n",
      "20250509 20250527\n",
      "20250509 20250602\n",
      "20250509 20250608\n",
      "20250509 20250614\n",
      "20250503 20250509\n",
      "20250503 20250515\n",
      "20250503 20250521\n",
      "20250503 20250527\n",
      "20250503 20250602\n",
      "20250503 20250608\n",
      "20250427 20250503\n",
      "20250427 20250509\n",
      "20250427 20250515\n",
      "20250427 20250521\n",
      "20250427 20250527\n",
      "20250427 20250602\n",
      "20250415 20250427\n",
      "20250415 20250503\n",
      "20250415 20250509\n",
      "20250415 20250515\n",
      "20250415 20250521\n",
      "The inter-annual interferometric pairs are (reference-secondary): \n",
      "The total number of interferometric pairs are:  38\n"
     ]
    }
   ],
   "source": [
    "sbas_pairs = set()\n",
    "\n",
    "print('The seasonal interferometric pairs are (reference-secondary): ')\n",
    "for reference, rt in stack_season.loc[::-1, ['sceneName', 'temporalBaseline']].itertuples(index=False):\n",
    "    secondaries = stack_season.loc[\n",
    "        (stack_season.sceneName != reference)\n",
    "        & (stack_season.temporalBaseline - rt <= max_temporal_baseline)\n",
    "        & (stack_season.temporalBaseline - rt > 0)\n",
    "    ]\n",
    "    for secondary in secondaries.sceneName:\n",
    "        sbas_pairs.add((reference, secondary))\n",
    "        print(reference[17:25], secondary[17:25])\n",
    "\n",
    "print('The inter-annual interferometric pairs are (reference-secondary): ')\n",
    "for reference, rt in stack_season.loc[::-1, ['sceneName', 'temporalBaseline']].itertuples(index=False):\n",
    "    secondaries = stack_season.loc[\n",
    "        (stack_season.sceneName != reference)\n",
    "        & (stack_season.temporalBaseline - rt <= interannual_baseline_max)\n",
    "        & (stack_season.temporalBaseline - rt > interannual_baseline_min)\n",
    "    ]\n",
    "    for secondary in secondaries.sceneName:\n",
    "        sbas_pairs.add((reference, secondary))\n",
    "        print(reference[17:25], secondary[17:25])\n",
    "\n",
    "print('The total number of interferometric pairs are: ', len(sbas_pairs))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "aaceeff8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           reference  \\\n",
      "0  S1A_IW_SLC__1SDV_20250521T053537_20250521T0536...   \n",
      "1  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...   \n",
      "2  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
      "3  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...   \n",
      "4  S1C_IW_SLC__1SDV_20250527T053437_20250527T0535...   \n",
      "\n",
      "                                           secondary  \n",
      "0  S1C_IW_SLC__1SDV_20250608T053437_20250608T0535...  \n",
      "1  S1A_IW_SLC__1SDV_20250521T053537_20250521T0536...  \n",
      "2  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...  \n",
      "3  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...  \n",
      "4  S1A_IW_SLC__1SDV_20250602T053537_20250602T0536...  \n"
     ]
    }
   ],
   "source": [
    "# Convert interferometric pairs set to DataFrame\n",
    "ifg_pairs_df = pd.DataFrame(list(sbas_pairs), columns=[\"reference\", \"secondary\"])\n",
    "print(ifg_pairs_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b8f0d511",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Modify the path \n",
    "ifg_pairs_df.to_csv(os.path.join(work_dir,\"interferometric_pairs.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d62e7e9",
   "metadata": {},
   "source": [
    "Downloading the stacks in stack_season "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create output folder\n",
    "os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "# Download loop\n",
    "for _, row in stack_season.iterrows():\n",
    "    url = row[\"url\"]\n",
    "    filename = os.path.join(download_dir, url.split(\"/\")[-1])\n",
    "\n",
    "    if not os.path.exists(filename):\n",
    "        print(f\"Downloading {filename} ...\")\n",
    "\n",
    "        with requests.get(url, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            total_size = int(r.headers.get(\"Content-Length\", 0))\n",
    "            chunk_size = 1024 * 1024  # 1 MB\n",
    "\n",
    "            with open(filename, 'wb') as f, tqdm(\n",
    "                desc=os.path.basename(filename),\n",
    "                total=total_size,\n",
    "                unit='B',\n",
    "                unit_scale=True,\n",
    "                unit_divisor=1024\n",
    "            ) as bar:\n",
    "                for chunk in r.iter_content(chunk_size=chunk_size):\n",
    "                    f.write(chunk)\n",
    "                    bar.update(len(chunk))\n",
    "    else:\n",
    "        print(f\"Already downloaded: {filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02d97bf",
   "metadata": {},
   "source": [
    "Some summaries of metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pathNumber flightDirection  scene_count\n",
      "0          66      DESCENDING           14\n",
      "1         139      DESCENDING           10\n"
     ]
    }
   ],
   "source": [
    "search_df_summary = (\n",
    "    search_df\n",
    "    .groupby(['pathNumber', 'flightDirection'])\n",
    "    .size()\n",
    "    .reset_index(name='scene_count')\n",
    "    .sort_values(by='scene_count', ascending=False)\n",
    ")\n",
    "\n",
    "print(search_df_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "88068881",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stack Season Summary:\n",
      "   pathNumber flightDirection  scene_count\n",
      "0          66      DESCENDING           10\n"
     ]
    }
   ],
   "source": [
    "stack_season_summary = (\n",
    "    stack_season\n",
    "    .groupby(['pathNumber', 'flightDirection'])\n",
    "    .size()\n",
    "    .reset_index(name='scene_count')\n",
    "    .sort_values(by='scene_count', ascending=False)\n",
    ")\n",
    "\n",
    "print(\"Stack Season Summary:\")\n",
    "print(stack_season_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4314b643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           reference  \\\n",
      "0  S1A_IW_SLC__1SDV_20250521T053537_20250521T0536...   \n",
      "1  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...   \n",
      "2  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...   \n",
      "3  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...   \n",
      "4  S1C_IW_SLC__1SDV_20250527T053437_20250527T0535...   \n",
      "\n",
      "                                           secondary  \n",
      "0  S1C_IW_SLC__1SDV_20250608T053437_20250608T0535...  \n",
      "1  S1A_IW_SLC__1SDV_20250521T053537_20250521T0536...  \n",
      "2  S1A_IW_SLC__1SDV_20250509T053537_20250509T0536...  \n",
      "3  S1C_IW_SLC__1SDV_20250515T053435_20250515T0535...  \n",
      "4  S1A_IW_SLC__1SDV_20250602T053537_20250602T0536...  \n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "sbas_df = pd.DataFrame(list(sbas_pairs), columns=[\"reference\", \"secondary\"])\n",
    "\n",
    "# Preview\n",
    "print(sbas_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d26e3b09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: ('S1A_IW_SLC__1SDV_20250521T053537_20250521T053604_059288_075B98_4642', 'S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E')\n",
      "2: ('S1C_IW_SLC__1SDV_20250503T053434_20250503T053501_002162_004973_6140', 'S1A_IW_SLC__1SDV_20250521T053537_20250521T053604_059288_075B98_4642')\n",
      "3: ('S1A_IW_SLC__1SDV_20250415T053537_20250415T053604_058763_074791_1397', 'S1A_IW_SLC__1SDV_20250509T053537_20250509T053604_059113_07558F_8B12')\n",
      "4: ('S1C_IW_SLC__1SDV_20250503T053434_20250503T053501_002162_004973_6140', 'S1C_IW_SLC__1SDV_20250515T053435_20250515T053502_002337_004EE6_7427')\n",
      "5: ('S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31', 'S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611')\n",
      "6: ('S1C_IW_SLC__1SDV_20250503T053434_20250503T053501_002162_004973_6140', 'S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611')\n",
      "7: ('S1A_IW_SLC__1SDV_20250509T053537_20250509T053604_059113_07558F_8B12', 'S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E')\n",
      "8: ('S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E', 'S1A_IW_SLC__1SDV_20250614T053536_20250614T053603_059638_0767A3_717C')\n",
      "9: ('S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31', 'S1A_IW_SLC__1SDV_20250614T053536_20250614T053603_059638_0767A3_717C')\n",
      "10: ('S1C_IW_SLC__1SDV_20250503T053434_20250503T053501_002162_004973_6140', 'S1A_IW_SLC__1SDV_20250509T053537_20250509T053604_059113_07558F_8B12')\n",
      "11: ('S1A_IW_SLC__1SDV_20250427T053538_20250427T053605_058938_074EBB_156D', 'S1C_IW_SLC__1SDV_20250503T053434_20250503T053501_002162_004973_6140')\n",
      "12: ('S1C_IW_SLC__1SDV_20250515T053435_20250515T053502_002337_004EE6_7427', 'S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E')\n",
      "... (truncated)\n",
      "Number of pairs: 38\n",
      "Type: <class 'tuple'>, Length: 2, Content: ('S1A_IW_SLC__1SDV_20250521T053537_20250521T053604_059288_075B98_4642', 'S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E')\n",
      "Type: <class 'tuple'>, Length: 2, Content: ('S1C_IW_SLC__1SDV_20250503T053434_20250503T053501_002162_004973_6140', 'S1A_IW_SLC__1SDV_20250521T053537_20250521T053604_059288_075B98_4642')\n",
      "Type: <class 'tuple'>, Length: 2, Content: ('S1A_IW_SLC__1SDV_20250415T053537_20250415T053604_058763_074791_1397', 'S1A_IW_SLC__1SDV_20250509T053537_20250509T053604_059113_07558F_8B12')\n",
      "Type of sbas_pairs: <class 'set'>\n",
      "Type of first element: <class 'tuple'>\n",
      "Length of first element: 2\n",
      "Contents of first element: ('S1A_IW_SLC__1SDV_20250521T053537_20250521T053604_059288_075B98_4642', 'S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E')\n",
      "Unique tuple lengths in sbas_pairs: {2}\n"
     ]
    }
   ],
   "source": [
    "for i, pair in enumerate(sbas_pairs):\n",
    "    print(f\"{i+1}: {pair}\")\n",
    "    if i > 10:  # Stop after 10 to avoid long output\n",
    "        print(\"... (truncated)\")\n",
    "        break\n",
    "\n",
    "# Check number of elements\n",
    "print(f\"Number of pairs: {len(sbas_pairs)}\")\n",
    "\n",
    "# Print one or two elements to see the structure\n",
    "for pair in list(sbas_pairs)[:3]:\n",
    "    print(f\"Type: {type(pair)}, Length: {len(pair)}, Content: {pair}\")\n",
    "\n",
    "\n",
    "print(f\"Type of sbas_pairs: {type(sbas_pairs)}\")\n",
    "first = next(iter(sbas_pairs))\n",
    "print(f\"Type of first element: {type(first)}\")\n",
    "print(f\"Length of first element: {len(first)}\")\n",
    "print(f\"Contents of first element: {first}\")\n",
    "\n",
    "lengths = set(len(pair) for pair in sbas_pairs)\n",
    "print(f\"Unique tuple lengths in sbas_pairs: {lengths}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040da42",
   "metadata": {},
   "source": [
    "Functions to download the DEM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d69cc080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTER GDEM Download Instructions\n",
      "1. Make sure you have a ~/.netrc file with your NASA Earthdata login credentials:\n",
      "\n",
      "machine urs.earthdata.nasa.gov\n",
      "login your_earthdata_username\n",
      "password your_earthdata_password\n",
      "\n",
      "2. Then run the following command in your shell:\n",
      "\n",
      "wget --load-cookies ~/.urs_cookies \\\n",
      "     --save-cookies ~/.urs_cookies \\\n",
      "     --keep-session-cookies \\\n",
      "     --auth-no-challenge=on \\\n",
      "     --user-agent=\"Mozilla/5.0\" \\\n",
      "     --netrc -c https://e4ftl01.cr.usgs.gov/ASTT/ASTGTM.003/2020.01.01/ASTGTMV003_N46E008_dem.tif\n",
      "\n",
      "Tile: ASTGTMV003_N46E008_dem.tif\n",
      "Output: Downloaded .tif file for the specified ASTER tile.\n"
     ]
    }
   ],
   "source": [
    "def print_aster_wget_instructions(lat_tile='N46', lon_tile='E008'):\n",
    "    \"\"\"\n",
    "    Print instructions and the exact wget command for downloading an ASTER GDEM tile.\n",
    "    \n",
    "    Args:\n",
    "        lat_tile (str): Latitude tile name, e.g., 'N46'\n",
    "        lon_tile (str): Longitude tile name, e.g., 'E008'\n",
    "    \"\"\"\n",
    "    date_path = \"2020.01.01\"\n",
    "    base_url = f\"https://e4ftl01.cr.usgs.gov/ASTT/ASTGTM.003/{date_path}\"\n",
    "    tile_name = f\"ASTGTMV003_{lat_tile}{lon_tile}_dem.tif\"\n",
    "\n",
    "    print(\"ASTER GDEM Download Instructions\")\n",
    "    print(\"1. Make sure you have a ~/.netrc file with your NASA Earthdata login credentials:\")\n",
    "    print(\"\"\"\n",
    "machine urs.earthdata.nasa.gov\n",
    "login your_earthdata_username\n",
    "password your_earthdata_password\n",
    "\"\"\")\n",
    "    print(\"2. Then run the following command in your shell:\\n\")\n",
    "    print(f\"\"\"wget --load-cookies ~/.urs_cookies \\\\\n",
    "     --save-cookies ~/.urs_cookies \\\\\n",
    "     --keep-session-cookies \\\\\n",
    "     --auth-no-challenge=on \\\\\n",
    "     --user-agent=\"Mozilla/5.0\" \\\\\n",
    "     --netrc -c {base_url}/{tile_name}\\n\"\"\")\n",
    "    print(\"Tile:\", tile_name)\n",
    "    print(\"Output: Downloaded .tif file for the specified ASTER tile.\")\n",
    "\n",
    "# Example usage\n",
    "print_aster_wget_instructions('N46', 'E008')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "15121552",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def download_dem_with_make_dem(W, E, S, N, download_dir, mode=1):\n",
    "    \"\"\"\n",
    "    Download DEM using GMTSAR's make_dem.csh script.\n",
    "\n",
    "    Parameters:\n",
    "    - W, E: Western and Eastern longitudes\n",
    "    - S, N: Southern and Northern latitudes\n",
    "    - download_dir: directory to save the DEM\n",
    "    - mode: resolution mode (1 = 1s, 2 = 3s), default is 1\n",
    "    \"\"\"\n",
    "    print(f\"[INFO] Downloading DEM for W:{W} E:{E} S:{S} N:{N} with mode {mode}\")\n",
    "    print(f\"[INFO] Output directory: {download_dir}\")\n",
    "    \n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    cmd = [\"make_dem.csh\", str(W), str(E), str(S), str(N), str(mode)]\n",
    "    \n",
    "    with tqdm(total=1, desc=\"DEM Download (make_dem.csh)\") as pbar:\n",
    "        subprocess.run(cmd, cwd=download_dir, check=True)\n",
    "        pbar.update(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9c53e13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "def download_earth_relief_dem(minlat, maxlat, minlon, maxlon, resolution='03s', download_dir='raw/dem/'):\n",
    "    \"\"\"\n",
    "    Download DEM using GMT's @earth_relief.\n",
    "\n",
    "    Args:\n",
    "        minlat, maxlat, minlon, maxlon: float, bounding box\n",
    "        resolution: str, e.g. '03s', '15s', etc.\n",
    "        download_dir: str, output directory (default: 'raw/dem/')\n",
    "    \"\"\"\n",
    "    \n",
    "    Path(download_dir).mkdir(parents=True, exist_ok=True)\n",
    "    print(\"GMT earth_relief DEM download:\")\n",
    "    print(f\"cd {download_dir}\")\n",
    "    print(f\"gmt grdcut @earth_relief_{resolution} -R{minlon}/{maxlon}/{minlat}/{maxlat} -Gdem_relief.grd\")\n",
    "\n",
    "    # Optional: auto-download with subprocess\n",
    "    # subprocess.run(['gmt', 'grdcut', f'@earth_relief_{resolution}',\n",
    "    #                 f'-R{minlon}/{maxlon}/{minlat}/{maxlat}', '-Gdem_relief.grd'],\n",
    "    #                cwd=download_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7d900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This one uses ISCE2 dem.py \n",
    "import subprocess\n",
    "\n",
    "cmd = [\n",
    "    \"python\", \"/path/to/isce2/applications/dem.py\",\n",
    "    \"-a\", \"SRTM1\",\n",
    "    \"-b\", \"44.1 47.2 6.2 10.5\",\n",
    "    \"-r\", \"1\",\n",
    "    \"-f\", \"dem_wide\"\n",
    "]\n",
    "\n",
    "subprocess.run(cmd, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "34b776c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Downloading DEM using make_dem.csh...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEM Download:   0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Downloading DEM for W:6 E:12 S:39 N:50 with mode 2\n",
      "[INFO] Output directory: /mnt/data/gmtsar_test_1/topo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "START: make_dem.csh\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "grdblend [NOTICE]: Remote data courtesy of GMT data server oceania [http://oceania.generic-mapping-tools.org]\n",
      "\n",
      "grdblend [NOTICE]: Earth Relief at 3x3 arc seconds tiles provided by SRTMGL3 (land only) [NASA/USGS].\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N39E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N39E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N40E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N40E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N41E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N41E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N41E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N42E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N42E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N42E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N42E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N42E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N43E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N43E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N43E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N43E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N43E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N43E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N44E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N44E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N44E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N44E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N44E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N44E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N45E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N45E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N45E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N45E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N45E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N45E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N46E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N46E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N46E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N46E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N46E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N46E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N47E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N47E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N47E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N47E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N47E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N47E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N48E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N48E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N48E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N48E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N48E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N48E011\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N49E006\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N49E007\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N49E008\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N49E009\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N49E010\n",
      "grdblend [NOTICE]:   -> Download 1x1 degree grid tile (earth_relief_03s_g): N49E011\n",
      "grdblend [NOTICE]: SRTM15 Earth Relief v2.7 original at 15x15 arc seconds [Tozer et al., 2019].\n",
      "grdblend [NOTICE]:   -> Download 10x10 degree grid tile (earth_relief_15s_p): N30E000\n",
      "grdblend [NOTICE]:   -> Download 10x10 degree grid tile (earth_relief_15s_p): N30E010\n",
      "DEM Download (make_dem.csh): 100%|| 1/1 [03:31<00:00, 211.58s/it]\n",
      "DEM Download: 100%|| 1/1 [03:31<00:00, 211.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "created dem.grd, heights relative to WGS84 ellipsoid\n",
      "\n",
      "END: make_dem.csh\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# === Download DEM using GMTSAR's make_dem.csh ===\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "\n",
    "print(\"\\n Downloading DEM using make_dem.csh...\")\n",
    "\n",
    "\n",
    "# for _ in tqdm(range(1), desc=\"DEM Download\"):\n",
    "#     download_dem_with_make_dem(\n",
    "#         W=bbox[0],\n",
    "#         E=bbox[2],\n",
    "#         S=bbox[1],\n",
    "#         N=bbox[3],\n",
    "#         download_dir=dem_dir,\n",
    "#         mode=1\n",
    "#     )\n",
    "\n",
    "for _ in tqdm(range(1), desc=\"DEM Download\"):\n",
    "    download_dem_with_make_dem(\n",
    "        6,\n",
    "        12,\n",
    "        39,\n",
    "        50,\n",
    "        download_dir=dem_dir,\n",
    "        mode=2\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca20cee",
   "metadata": {},
   "source": [
    "Downloading precise orbit using sentineleof 0.11.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de00df11",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Need to instal: pip install --upgrade sentineleof ver 0.11.0 for S1C\n",
    "\n",
    "# === Download orbits for all SLCs under /raw ===\n",
    "\n",
    "print(\"\\n Searching for SLC path folders to fetch orbits...\")\n",
    "#from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "paths = glob.glob(os.path.join(download_dir, \"path_*\"))\n",
    "\n",
    "for download_dir in tqdm(paths, desc=\"Orbit Download\", unit=\"path\"):\n",
    "    tqdm.write(f\"Downloading orbits for: {download_dir}\")\n",
    "    subprocess.run([\n",
    "        \"eof\",\n",
    "        \"--search-path\", download_dir,\n",
    "        \"--save-dir\", orbit_dir,\n",
    "        \"--force-asf\"\n",
    "    ], check=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbf5347b",
   "metadata": {},
   "source": [
    "Select a pair before and after an incident "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9acc2c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference (before landslide): S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31 2025-05-27 05:34:37\n",
      "Secondary (after landslide): S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611 2025-06-02 05:35:37\n"
     ]
    }
   ],
   "source": [
    "incident_date = pd.to_datetime(\"2025-05-28\")\n",
    "\n",
    "before_scene = stack_season[stack_season['startTime'] < incident_date].sort_values('startTime').iloc[-1]\n",
    "after_scene = stack_season[stack_season['startTime'] > incident_date].sort_values('startTime').iloc[0]\n",
    "\n",
    "print(\"Reference (before landslide):\", before_scene['sceneName'], before_scene['startTime'])\n",
    "print(\"Secondary (after landslide):\", after_scene['sceneName'], after_scene['startTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "df45fa50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference (before landslide) S1A: S1A_IW_SLC__1SDV_20250521T053537_20250521T053604_059288_075B98_4642 2025-05-21 05:35:37\n",
      "Secondary (after landslide) S1A: S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611 2025-06-02 05:35:37\n"
     ]
    }
   ],
   "source": [
    "before_scene_A = stack_season[(stack_season['platform'] == 'Sentinel-1A') & \n",
    "                                (stack_season['startTime'] < incident_date)].sort_values('startTime').iloc[-1]\n",
    "after_scene_A  = stack_season[(stack_season['platform'] == 'Sentinel-1A') & \n",
    "                                (stack_season['startTime'] > incident_date)].sort_values('startTime').iloc[0]\n",
    "\n",
    "print(\"Reference (before landslide) S1A:\", before_scene_A['sceneName'], before_scene_A['startTime'])\n",
    "print(\"Secondary (after landslide) S1A:\", after_scene_A['sceneName'], after_scene_A['startTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "682f43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference (before landslide) S1C: S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31 2025-05-27 05:34:37\n",
      "Secondary (after landslide) S1C: S1C_IW_SLC__1SDV_20250608T053437_20250608T053504_002687_0058C3_BB3E 2025-06-08 05:34:37\n"
     ]
    }
   ],
   "source": [
    "before_scene_C = stack_season[(stack_season['platform'] == 'Sentinel-1C') & \n",
    "                                (stack_season['startTime'] < incident_date)].sort_values('startTime').iloc[-1]\n",
    "after_scene_C  = stack_season[(stack_season['platform'] == 'Sentinel-1C') & \n",
    "                                (stack_season['startTime'] > incident_date)].sort_values('startTime').iloc[0]\n",
    "\n",
    "print(\"Reference (before landslide) S1C:\", before_scene_C['sceneName'], before_scene_C['startTime'])\n",
    "print(\"Secondary (after landslide) S1C:\", after_scene_C['sceneName'], after_scene_C['startTime'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71148f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# P2P processing directory\n",
    "p2p_dir = os.path.join(work_dir, \"p2p\")\n",
    "os.makedirs(p2p_dir, exist_ok=True)\n",
    "\n",
    "# Use the actual zip file names from your search results\n",
    "scene_names = [before_scene['sceneName'], after_scene['sceneName']]\n",
    "\n",
    "# Link .zip files (SAFE archives)\n",
    "for scene_name in scene_names:\n",
    "    zip_file = scene_name + \".zip\"\n",
    "    src = os.path.join(download_dir, zip_file)\n",
    "    dst = os.path.join(p2p_dir, zip_file)\n",
    "    if not os.path.exists(dst):\n",
    "        os.symlink(src, dst)\n",
    "\n",
    "# Link orbit .EOF files as before\n",
    "for file in os.listdir(download_dir):\n",
    "    if file.endswith(\".EOF\"):\n",
    "        src = os.path.join(download_dir, file)\n",
    "        dst = os.path.join(p2p_dir, file)\n",
    "        if not os.path.exists(dst):\n",
    "            os.symlink(src, dst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8897f967",
   "metadata": {},
   "outputs": [],
   "source": [
    "pair_name = f\"p2p_{before_scene['platform']}_{after_scene['platform']}\"\n",
    "p2p_dir = os.path.join(work_dir, pair_name)\n",
    "os.makedirs(p2p_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a4aad843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created: /mnt/data/gmtsar_test_1/p2p/p2p.txt\n",
      "Created p2p.txt with:\n",
      "- S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31.zip\n",
      "- S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611.zip\n"
     ]
    }
   ],
   "source": [
    "p2p_txt = os.path.join(p2p_dir, \"p2p.txt\")\n",
    "with open(p2p_txt, \"w\") as f:\n",
    "    f.write(before_scene['fileName'] + \"\\n\")\n",
    "    f.write(after_scene['fileName'] + \"\\n\")\n",
    "print(f\"Created: {p2p_txt}\")\n",
    "print(f\"Created p2p.txt with:\\n- {before_scene['fileName']}\\n- {after_scene['fileName']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6dd4c5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running prep_raw_S1_TOPS.csh for master...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'prep_raw_S1_TOPS.csh'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Run prep_raw_S1_TOPS.csh on both scenes\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning prep_raw_S1_TOPS.csh for master...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprep_raw_S1_TOPS.csh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmaster_safe\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRunning prep_raw_S1_TOPS.csh for slave...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m subprocess.run([\u001b[33m\"\u001b[39m\u001b[33mprep_raw_S1_TOPS.csh\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(slave_safe)], check=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/insar/lib/python3.13/subprocess.py:554\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    551\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstdout\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m    552\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mstderr\u001b[39m\u001b[33m'\u001b[39m] = PIPE\n\u001b[32m--> \u001b[39m\u001b[32m554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpopenargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    556\u001b[39m         stdout, stderr = process.communicate(\u001b[38;5;28minput\u001b[39m, timeout=timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/insar/lib/python3.13/subprocess.py:1039\u001b[39m, in \u001b[36mPopen.__init__\u001b[39m\u001b[34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[39m\n\u001b[32m   1035\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.text_mode:\n\u001b[32m   1036\u001b[39m             \u001b[38;5;28mself\u001b[39m.stderr = io.TextIOWrapper(\u001b[38;5;28mself\u001b[39m.stderr,\n\u001b[32m   1037\u001b[39m                     encoding=encoding, errors=errors)\n\u001b[32m-> \u001b[39m\u001b[32m1039\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1040\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1041\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1042\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1043\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1044\u001b[39m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1045\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1046\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1047\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1048\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1049\u001b[39m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[32m   1050\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m.stdin, \u001b[38;5;28mself\u001b[39m.stdout, \u001b[38;5;28mself\u001b[39m.stderr)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/insar/lib/python3.13/subprocess.py:1969\u001b[39m, in \u001b[36mPopen._execute_child\u001b[39m\u001b[34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session, process_group)\u001b[39m\n\u001b[32m   1967\u001b[39m     err_msg = os.strerror(errno_num)\n\u001b[32m   1968\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m err_filename \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1969\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[32m   1970\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1971\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'prep_raw_S1_TOPS.csh'"
     ]
    }
   ],
   "source": [
    "#  Cell 1: Stitch the SAFE folders using prep_raw_S1_TOPS\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Define the master and slave scene .SAFE folders\n",
    "master_safe = next(Path(download_dir).glob(\"S1C_IW_SLC__1SDV_20250527T053437_*.SAFE\"))\n",
    "slave_safe = next(Path(download_dir).glob(\"S1A_IW_SLC__1SDV_20250602T053537_*.SAFE\"))\n",
    "\n",
    "# Run prep_raw_S1_TOPS.csh on both scenes\n",
    "print(\"Running prep_raw_S1_TOPS.csh for master...\")\n",
    "subprocess.run([\"prep_raw_S1_TOPS.csh\", str(master_safe)], check=True)\n",
    "\n",
    "print(\"Running prep_raw_S1_TOPS.csh for slave...\")\n",
    "subprocess.run([\"prep_raw_S1_TOPS.csh\", str(slave_safe)], check=True)\n",
    "\n",
    "print(\" SAFE scenes stitched. Ready for p2p processing.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2bd18941",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running p2p_S1_TOPS_Frame.csh with:\n",
      "Master  : S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31\n",
      "Secondary: S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611\n",
      "\n",
      "Usage: p2p_S1_TOPS_Frame.csh Master.SAFE Master.EOF Aligned.SAFE Aligned.EOF config.s1a.txt polarization parallel\n",
      "\n",
      "Example: p2p_S1_TOPS_Frame.csh S1A_IW_SLC__1SDV_20150607T014936_20150607T015003_006261_00832E_3626.SAFE S1A_OPER_AUX_POEORB_OPOD_20150615T155109_V20150525T225944_20150527T005944.EOF S1A_IW_SLC__1SSV_20150526T014935_20150526T015002_006086_007E23_679A.SAFE S1A_OPER_AUX_POEORB_OPOD_20150627T155155_V20150606T225944_20150608T005944.EOF config.s1a.txt vv 1\n",
      "\n",
      "    Place the .SAFE file in the raw folder, DEM in the topo folder\n",
      "    During processing, F1, F2, F3 and merge folder will be generated\n",
      "    Final results will be placed in the merge folder, with phase\n",
      "    corr [unwrapped phase].\n",
      "    polarization = vv vh hh or hv \n",
      "    parallel = 0-sequential  1-parallel \n",
      "\n",
      "Reference: Xu, X., Sandwell, D.T., Tymofyeyeva, E., Gonzlez-Ortega, A. and Tong, X., \n",
      "    2017. Tectonic and Anthropogenic Deformation at the Cerro Prieto Geothermal \n",
      "    Step-Over Revealed by Sentinel-1A InSAR. IEEE Transactions on Geoscience and Remote Sensing.\n",
      "\n"
     ]
    },
    {
     "ename": "CalledProcessError",
     "evalue": "Command '['p2p_S1_TOPS_Frame.csh', 'S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31', 'S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611']' returned non-zero exit status 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mCalledProcessError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[94]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMaster  : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreference\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mSecondary: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msecondary\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mp2p_S1_TOPS_Frame.csh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreference\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msecondary\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwork_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/insar/lib/python3.13/subprocess.py:577\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    575\u001b[39m     retcode = process.poll()\n\u001b[32m    576\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m check \u001b[38;5;129;01mand\u001b[39;00m retcode:\n\u001b[32m--> \u001b[39m\u001b[32m577\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m CalledProcessError(retcode, process.args,\n\u001b[32m    578\u001b[39m                                  output=stdout, stderr=stderr)\n\u001b[32m    579\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m CompletedProcess(process.args, retcode, stdout, stderr)\n",
      "\u001b[31mCalledProcessError\u001b[39m: Command '['p2p_S1_TOPS_Frame.csh', 'S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31', 'S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611']' returned non-zero exit status 1."
     ]
    }
   ],
   "source": [
    "reference = before_scene['sceneName'].replace(\".zip\", \"\")\n",
    "secondary = after_scene['sceneName'].replace(\".zip\", \"\")\n",
    "\n",
    "print(f\" Running p2p_S1_TOPS_Frame.csh with:\")\n",
    "print(f\"Master  : {reference}\")\n",
    "print(f\"Secondary: {secondary}\")\n",
    "\n",
    "subprocess.run([\"p2p_S1_TOPS_Frame.csh\", reference, secondary], cwd=work_dir, check=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2efdfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#  Cell 2: Run p2p_processing.csh\n",
    "from pathlib import Path\n",
    "import subprocess\n",
    "\n",
    "# Extract stems (filenames without extension) from stitched products\n",
    "master_stem = Path(master_safe).stem\n",
    "slave_stem = Path(slave_safe).stem\n",
    "\n",
    "print(\"Running p2p_processing.csh ...\")\n",
    "subprocess.run([\n",
    "    \"p2p_processing.csh\",\n",
    "    \"S1_TOPS\",\n",
    "    master_stem,\n",
    "    slave_stem\n",
    "], cwd=work_dir, check=True)\n",
    "\n",
    "print(\" GMTSAR p2p processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "0b526703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Extracting S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31.zip ...\n",
      " Extracting S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611.zip ...\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Define SAFE filenames\n",
    "master_zip = f\"{before_scene['sceneName']}.zip\"\n",
    "slave_zip = f\"{after_scene['sceneName']}.zip\"\n",
    "\n",
    "# Paths\n",
    "master_path = Path(download_dir) / master_zip\n",
    "slave_path = Path(download_dir) / slave_zip\n",
    "\n",
    "# Unzip if needed\n",
    "for zip_path in [master_path, slave_path]:\n",
    "    target_dir = zip_path.with_suffix(\".SAFE\")\n",
    "    if not target_dir.exists():\n",
    "        print(f\" Extracting {zip_path.name} ...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(download_dir)\n",
    "    else:\n",
    "        print(f\" Already unzipped: {target_dir.name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e4a134a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Master (reference): S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31\n",
      "Slave (secondary): S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611\n",
      "\n",
      "\n",
      "PREPROCESS - START\n",
      "\n",
      "Working on images S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31 S1A_IW_SLC__1SDV_20250602T053537_20250602T053604_059463_0761AE_4611 ...\n",
      " no file  raw/S1C_IW_SLC__1SDV_20250527T053437_20250527T053504_002512_0053BB_AD31.xml\n",
      "GMTSAR p2p processing completed.\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# SAT type for Sentinel-1 IW SLCs\n",
    "sat = \"S1_TOPS\"\n",
    "\n",
    "# Strip .zip from filenames\n",
    "master = before_scene['fileName'].replace(\".zip\", \"\")\n",
    "slave = after_scene['fileName'].replace(\".zip\", \"\")\n",
    "\n",
    "print(f\"Master (reference): {master}\")\n",
    "print(f\"Slave (secondary): {slave}\")\n",
    "\n",
    "cmd = [\"p2p_processing.csh\", sat, master, slave]\n",
    "\n",
    "try:\n",
    "    subprocess.run(cmd, cwd=work_dir, check=True)\n",
    "    print(\"GMTSAR p2p processing completed.\")\n",
    "except subprocess.CalledProcessError as e:\n",
    "    print(f\"Processing failed: {e}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9cb287",
   "metadata": {},
   "source": [
    "##NOW TESTING AGAIN IN A NEW DIRECTORY BASED ON https://gmtsar.github.io/documentation/S1_Batch_Preprocessing.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ae6723a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory structure created under: /mnt/data/gmtsar_test_2\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "# Define root\n",
    "root_data = Path(\"/mnt/data\")\n",
    "project_dir = root_data / \"gmtsar_test_2\"\n",
    "\n",
    "# Define top-level directories\n",
    "top_dirs = [\"data\", \"orbit\", \"reframed\", \"topo\", \"F1\", \"F2\", \"F3\", \"SBAS\", \"merge\"]\n",
    "\n",
    "# Define F* subdirectories\n",
    "f_subdirs = [\"raw\", \"SLC\", \"intf_in\", \"topo\"]\n",
    "\n",
    "# Create top-level dirs\n",
    "for d in top_dirs:\n",
    "    (project_dir / d).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create F1/F2/F3 substructure\n",
    "for f in [\"F1\", \"F2\", \"F3\"]:\n",
    "    for sub in f_subdirs:\n",
    "        (project_dir / f / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Touch the batch_tops.config file inside each F*\n",
    "for f in [\"F1\", \"F2\", \"F3\"]:\n",
    "    config_file = project_dir / f / \"batch_tops.config\"\n",
    "    config_file.touch()\n",
    "\n",
    "print(f\"Directory structure created under: {project_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "12a42d03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[01;34m/mnt/data/gmtsar_test_2\u001b[0m\n",
      " \u001b[01;34mF1\u001b[0m\n",
      "  \u001b[01;34mSLC\u001b[0m\n",
      "  \u001b[01;34mintf_in\u001b[0m\n",
      "  \u001b[01;34mraw\u001b[0m\n",
      "  \u001b[01;34mtopo\u001b[0m\n",
      " \u001b[01;34mF2\u001b[0m\n",
      "  \u001b[01;34mSLC\u001b[0m\n",
      "  \u001b[01;34mintf_in\u001b[0m\n",
      "  \u001b[01;34mraw\u001b[0m\n",
      "  \u001b[01;34mtopo\u001b[0m\n",
      " \u001b[01;34mF3\u001b[0m\n",
      "  \u001b[01;34mSLC\u001b[0m\n",
      "  \u001b[01;34mintf_in\u001b[0m\n",
      "  \u001b[01;34mraw\u001b[0m\n",
      "  \u001b[01;34mtopo\u001b[0m\n",
      " \u001b[01;34mSBAS\u001b[0m\n",
      " \u001b[01;34mdata\u001b[0m\n",
      " \u001b[01;34mmerge\u001b[0m\n",
      " \u001b[01;34morbit\u001b[0m\n",
      " \u001b[01;34mreframed\u001b[0m\n",
      " \u001b[01;34mtopo\u001b[0m\n",
      "\n",
      "21 directories\n"
     ]
    }
   ],
   "source": [
    "!tree -d -L 3 /mnt/data/gmtsar_test_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963529ac",
   "metadata": {},
   "source": [
    "Get the satellite footpring from LED file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e315777b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Swath ALL] Start ECEF: [-4654596.487311, -223083.269757, 5315068.231733], End ECEF: [5351057.468749, -620367.425822, -4596147.382489]\n",
      "[Swath ALL] W: -177.2561, E: -6.613, S: -40.6421, N: 48.9294\n",
      "[Swath ALL] Start ECEF: [-4714040.444577, -247922.081594, 5261442.231315], End ECEF: [5405304.917568, -606441.635012, -4534014.418914]\n",
      "[Swath ALL] W: -176.9895, E: -6.4015, S: -39.9842, N: 48.2738\n",
      "[Swath 053438] Start ECEF: [-4654596.487311, -223083.269757, 5315068.231733], End ECEF: [5351057.468749, -620367.425822, -4596147.382489]\n",
      "[Swath 053438] W: -177.2561, E: -6.613, S: -40.6421, N: 48.9294\n",
      "[Swath 053538] Start ECEF: [-4714040.444577, -247922.081594, 5261442.231315], End ECEF: [5405304.917568, -606441.635012, -4534014.418914]\n",
      "[Swath 053538] W: -176.9895, E: -6.4015, S: -39.9842, N: 48.2738\n",
      "\n",
      "[Combined Coverage for All Swaths]\n",
      "W: -177.2561, E: -6.4015, S: -40.6421, N: 48.9294\n",
      "\n",
      "[DEM grdinfo Output]\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: Title: Produced by grdmath\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: Command: grdmath -Vq dem_ortho.grd geoid_resamp.grd ADD = dem.grd\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: Remark: \n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: Gridline node registration used [Geographic grid]\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: Grid file format: nf = GMT netCDF format (32-bit float), CF-1.7\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: x_min: 6.40833333333 x_max: 10.2541666667 x_inc: 0.000277777777778 (1 sec) name: longitude n_columns: 13846\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: y_min: 44.3125 y_max: 46.9958333333 y_inc: 0.000277777777778 (1 sec) name: latitude n_rows: 9661\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: v_min: -906.03137207 v_max: 4849.56152344 name: z\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: scale_factor: 1 add_offset: 0\n",
      "/mnt/data/gmtsar_test_1/F1/topo/dem.grd: format: netCDF-4 chunk_size: 129,129 shuffle: on deflation_level: 3\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "from pyproj import Transformer\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Set your raw directory path (adjust if needed)\n",
    "raw_dir = \"/mnt/data/gmtsar_test_1/F1/raw\"\n",
    "led_files = [f for f in os.listdir(raw_dir) if f.endswith(\"F1.LED\")]\n",
    "\n",
    "# Transformer from ECEF to lat/lon\n",
    "transformer = Transformer.from_crs(\"epsg:4978\", \"epsg:4326\", always_xy=True)\n",
    "\n",
    "swath_bounds = {}\n",
    "\n",
    "for led_file in led_files:\n",
    "    swath = led_file.split(\"_\")[2]  # E.g., 053438\n",
    "    path = os.path.join(raw_dir, led_file)\n",
    "\n",
    "    # Extract first and last line ECEF coordinates\n",
    "    awk_cmd = f\"awk 'NR==2{{print $4, $5, $6}} END{{print $4, $5, $6}}' {path}\"\n",
    "    result = subprocess.check_output(awk_cmd, shell=True).decode().strip().split(\"\\n\")\n",
    "    xyz_start = list(map(float, result[0].split()))\n",
    "    xyz_end = list(map(float, result[1].split()))\n",
    "    print(f\"[Swath {swath}] Start ECEF: {xyz_start}, End ECEF: {xyz_end}\")\n",
    "    # Convert to lat/lon\n",
    "    lon1, lat1, _ = transformer.transform(xyz_start[0], xyz_start[1], xyz_start[2])\n",
    "    lon2, lat2, _ = transformer.transform(xyz_end[0], xyz_end[1], xyz_end[2])\n",
    "\n",
    "    # Get bounding box\n",
    "    W = round(min(lon1, lon2), 4)\n",
    "    E = round(max(lon1, lon2), 4)\n",
    "    S = round(min(lat1, lat2), 4)\n",
    "    N = round(max(lat1, lat2), 4)\n",
    "\n",
    "    swath_bounds[swath] = {\"W\": W, \"E\": E, \"S\": S, \"N\": N}\n",
    "    print(f\"[Swath {swath}] W: {W}, E: {E}, S: {S}, N: {N}\")\n",
    "\n",
    "# === Merge bounding boxes ===\n",
    "W_all = min(b[\"W\"] for b in swath_bounds.values())\n",
    "E_all = max(b[\"E\"] for b in swath_bounds.values())\n",
    "S_all = min(b[\"S\"] for b in swath_bounds.values())\n",
    "N_all = max(b[\"N\"] for b in swath_bounds.values())\n",
    "\n",
    "print(\"\\n[Combined Coverage for All Swaths]\")\n",
    "print(f\"W: {W_all}, E: {E_all}, S: {S_all}, N: {N_all}\")\n",
    "\n",
    "# === Check DEM coverage using GMT ===\n",
    "dem_path = \"/mnt/data/gmtsar_test_1/F1/topo/dem.grd\"\n",
    "try:\n",
    "    grdinfo = subprocess.check_output(f\"gmt grdinfo {dem_path}\", shell=True).decode()\n",
    "    print(\"\\n[DEM grdinfo Output]\")\n",
    "    print(grdinfo)\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"[ERROR] Could not read dem.grd  check path or GMT install.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1b74ac3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           sceneName     platform  \\\n",
      "0  S1A_IW_SLC__1SDV_20250415T053537_20250415T0536...  Sentinel-1A   \n",
      "1  S1A_IW_SLC__1SDV_20250427T053538_20250427T0536...  Sentinel-1A   \n",
      "2  S1C_IW_SLC__1SDV_20250503T053434_20250503T0535...  Sentinel-1C   \n",
      "\n",
      "   temporalBaseline  \n",
      "0                 0  \n",
      "1                12  \n",
      "2                18  \n"
     ]
    }
   ],
   "source": [
    "#print(\"Available columns:\\n\", stack_season.columns.tolist())\n",
    "print(stack_season[['sceneName', 'platform', 'temporalBaseline']].head(3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "insar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
