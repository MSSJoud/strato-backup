{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82641ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed (first run):\n",
    "# !pip install xarray netCDF4 h5py numpy pandas\n",
    "\n",
    "import os, math, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py, xarray as xr\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d5b6f2dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASE: C:\\Users\\jr80fd\\swin_test\n",
      "INSAR_H5: C:\\Users\\jr80fd\\swin_test\\timeseries_ERA5_ramp_demErr.h5\n",
      "W3RA_DIR: C:\\Users\\jr80fd\\swin_test\\w3ra\n"
     ]
    }
   ],
   "source": [
    "BASE = Path(r\"C:\\Users\\jr80fd\\swin_test\")\n",
    "INSAR_H5 = BASE / \"timeseries_ERA5_ramp_demErr.h5\"\n",
    "\n",
    "W3RA_DIR = BASE / \"w3ra\"\n",
    "geom_path = Path(r\"C:\\Users\\JR80FD\\swin_test\\inputs\\geometryGeo.h5\")\n",
    "\n",
    "\n",
    "print(f\"BASE: {BASE}\")\n",
    "print(f\"INSAR_H5: {INSAR_H5}\")      \n",
    "\n",
    "print(f\"W3RA_DIR: {W3RA_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c363a31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def walk_h5(fn):\n",
    "    with h5py.File(fn, 'r') as f:\n",
    "        print(\"HDF5 file:\", fn)\n",
    "        def _walk(name, obj):\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"[DATASET] {name}  shape={obj.shape}  dtype={obj.dtype}\")\n",
    "                for k,v in obj.attrs.items():\n",
    "                    if k in (\"rows\",\"cols\",\"length\",\"mintpy.meta\"):  # common MintPy attrs\n",
    "                        print(f\"   attr {k}: {v}\")\n",
    "            elif isinstance(obj, h5py.Group):\n",
    "                print(f\"[GROUP]   {name}\")\n",
    "        f.visititems(_walk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c16da0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 file: C:\\Users\\jr80fd\\swin_test\\timeseries_ERA5_ramp_demErr.h5\n",
      "[DATASET] bperp  shape=(156,)  dtype=float32\n",
      "[DATASET] date  shape=(156,)  dtype=|S8\n",
      "[DATASET] timeseries  shape=(156, 2939, 3713)  dtype=float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "walk_h5(INSAR_H5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999bd60f",
   "metadata": {},
   "source": [
    "# 1) Inspect the InSAR HDF5 structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7185cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_h5(path):\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        print(f\"File: {path}\")\n",
    "        print(\"Top-level keys:\", list(f.keys()))\n",
    "        for k in f.keys():\n",
    "            obj = f[k]\n",
    "            if isinstance(obj, h5py.Dataset):\n",
    "                print(f\"  Dataset: {k:18s} shape={obj.shape} dtype={obj.dtype}\")\n",
    "                if obj.attrs:\n",
    "                    a = {k2: obj.attrs[k2] for k2 in obj.attrs.keys()}\n",
    "                    print(\"    attrs keys:\", list(a.keys())[:8])\n",
    "            else:\n",
    "                print(f\"  Group:   {k}\")\n",
    "        # common MintPy fields\n",
    "        if \"date\" in f:\n",
    "            raw = f[\"date\"][:]\n",
    "            dates = [d.decode() if isinstance(d, (bytes, np.bytes_)) else str(d) for d in raw]\n",
    "            print(f\"\\nFound {len(dates)} dates. First/last: {dates[:3]} ... {dates[-3:]}\")\n",
    "        if \"timeseries\" in f:\n",
    "            print(\"timeseries shape:\", f[\"timeseries\"].shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c6a0226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File: C:\\Users\\jr80fd\\swin_test\\timeseries_ERA5_ramp_demErr.h5\n",
      "Top-level keys: ['bperp', 'date', 'timeseries']\n",
      "  Dataset: bperp              shape=(156,) dtype=float32\n",
      "  Dataset: date               shape=(156,) dtype=|S8\n",
      "  Dataset: timeseries         shape=(156, 2939, 3713) dtype=float32\n",
      "\n",
      "Found 156 dates. First/last: ['20170610', '20170622', '20170704'] ... ['20220912', '20221006', '20221018']\n",
      "timeseries shape: (156, 2939, 3713)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "summarize_h5(INSAR_H5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bcea84f",
   "metadata": {},
   "source": [
    "# 2) Load InSAR as an xarray.DataArray [time, y, x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b7b7260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_insar_h5_as_xarray(path: Path) -> xr.DataArray:\n",
    "    with h5py.File(path, \"r\") as f:\n",
    "        # dates\n",
    "        if \"date\" not in f:\n",
    "            raise ValueError(\"No 'date' dataset found in HDF5.\")\n",
    "        raw = f[\"date\"][:]\n",
    "        dates = [d.decode() if isinstance(d, (bytes, np.bytes_)) else str(d) for d in raw]\n",
    "        # MintPy often uses YYYYMMDD\n",
    "        time = pd.to_datetime(dates, format=\"%Y%m%d\", errors=\"coerce\")\n",
    "        # data\n",
    "        ts = f[\"timeseries\"][:]  # either (T,H,W) or (H,W,T)\n",
    "        if ts.ndim != 3:\n",
    "            raise ValueError(\"Expected 3D timeseries.\")\n",
    "        # infer axis order\n",
    "        T, H, W = None, None, None\n",
    "        if ts.shape[0] == len(time):        # (T,H,W)\n",
    "            T, H, W = ts.shape\n",
    "            data = ts\n",
    "        elif ts.shape[-1] == len(time):     # (H,W,T)\n",
    "            H, W, T = ts.shape\n",
    "            data = np.transpose(ts, (2,0,1))   # -> (T,H,W)\n",
    "        else:\n",
    "            raise ValueError(\"Could not infer time axis. Check shapes/dates.\")\n",
    "\n",
    "        # build y/x coords (try attributes, else pixel indices)\n",
    "        H5_attrs = f[\"timeseries\"].attrs\n",
    "        def get_attr(name, default=None):\n",
    "            return H5_attrs[name] if name in H5_attrs else default\n",
    "\n",
    "        # MintPy geocoded often has: X_FIRST, Y_FIRST, X_STEP, Y_STEP (lon/lat grid)\n",
    "        x_first = get_attr(\"X_FIRST\", None)\n",
    "        y_first = get_attr(\"Y_FIRST\", None)\n",
    "        x_step  = get_attr(\"X_STEP\", None)\n",
    "        y_step  = get_attr(\"Y_STEP\", None)\n",
    "        if None not in (x_first, y_first, x_step, y_step):\n",
    "            x = x_first + np.arange(W) * x_step\n",
    "            y = y_first + np.arange(H) * y_step\n",
    "        else:\n",
    "            # fallback pixel indices\n",
    "            x = np.arange(W)\n",
    "            y = np.arange(H)\n",
    "\n",
    "    da = xr.DataArray(\n",
    "        data,\n",
    "        dims=(\"time\",\"y\",\"x\"),\n",
    "        coords={\"time\": time, \"y\": y, \"x\": x},\n",
    "        name=\"insar_deformation\"\n",
    "    )\n",
    "    return da\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb1de068",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><svg style=\"position: absolute; width: 0; height: 0; overflow: hidden\">\n",
       "<defs>\n",
       "<symbol id=\"icon-database\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M16 0c-8.837 0-16 2.239-16 5v4c0 2.761 7.163 5 16 5s16-2.239 16-5v-4c0-2.761-7.163-5-16-5z\"></path>\n",
       "<path d=\"M16 17c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "<path d=\"M16 26c-8.837 0-16-2.239-16-5v6c0 2.761 7.163 5 16 5s16-2.239 16-5v-6c0 2.761-7.163 5-16 5z\"></path>\n",
       "</symbol>\n",
       "<symbol id=\"icon-file-text2\" viewBox=\"0 0 32 32\">\n",
       "<path d=\"M28.681 7.159c-0.694-0.947-1.662-2.053-2.724-3.116s-2.169-2.030-3.116-2.724c-1.612-1.182-2.393-1.319-2.841-1.319h-15.5c-1.378 0-2.5 1.121-2.5 2.5v27c0 1.378 1.122 2.5 2.5 2.5h23c1.378 0 2.5-1.122 2.5-2.5v-19.5c0-0.448-0.137-1.23-1.319-2.841zM24.543 5.457c0.959 0.959 1.712 1.825 2.268 2.543h-4.811v-4.811c0.718 0.556 1.584 1.309 2.543 2.268zM28 29.5c0 0.271-0.229 0.5-0.5 0.5h-23c-0.271 0-0.5-0.229-0.5-0.5v-27c0-0.271 0.229-0.5 0.5-0.5 0 0 15.499-0 15.5 0v7c0 0.552 0.448 1 1 1h7v19.5z\"></path>\n",
       "<path d=\"M23 26h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 22h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "<path d=\"M23 18h-14c-0.552 0-1-0.448-1-1s0.448-1 1-1h14c0.552 0 1 0.448 1 1s-0.448 1-1 1z\"></path>\n",
       "</symbol>\n",
       "</defs>\n",
       "</svg>\n",
       "<style>/* CSS stylesheet for displaying xarray objects in jupyterlab.\n",
       " *\n",
       " */\n",
       "\n",
       ":root {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base rgba(0, 0, 0, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(0, 0, 0, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, white)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, white) h s calc(l - 15))\n",
       "  );\n",
       "}\n",
       "\n",
       "html[theme=\"dark\"],\n",
       "html[data-theme=\"dark\"],\n",
       "body[data-theme=\"dark\"],\n",
       "body.vscode-dark {\n",
       "  --xr-font-color0: var(\n",
       "    --jp-content-font-color0,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 1))\n",
       "  );\n",
       "  --xr-font-color2: var(\n",
       "    --jp-content-font-color2,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.54))\n",
       "  );\n",
       "  --xr-font-color3: var(\n",
       "    --jp-content-font-color3,\n",
       "    var(--pst-color-text-base, rgba(255, 255, 255, 0.38))\n",
       "  );\n",
       "  --xr-border-color: var(\n",
       "    --jp-border-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 10))\n",
       "  );\n",
       "  --xr-disabled-color: var(\n",
       "    --jp-layout-color3,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 40))\n",
       "  );\n",
       "  --xr-background-color: var(\n",
       "    --jp-layout-color0,\n",
       "    var(--pst-color-on-background, #111111)\n",
       "  );\n",
       "  --xr-background-color-row-even: var(\n",
       "    --jp-layout-color1,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 5))\n",
       "  );\n",
       "  --xr-background-color-row-odd: var(\n",
       "    --jp-layout-color2,\n",
       "    hsl(from var(--pst-color-on-background, #111111) h s calc(l + 15))\n",
       "  );\n",
       "}\n",
       "\n",
       ".xr-wrap {\n",
       "  display: block !important;\n",
       "  min-width: 300px;\n",
       "  max-width: 700px;\n",
       "}\n",
       "\n",
       ".xr-text-repr-fallback {\n",
       "  /* fallback to plain text repr when CSS is not injected (untrusted notebook) */\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-header {\n",
       "  padding-top: 6px;\n",
       "  padding-bottom: 6px;\n",
       "  margin-bottom: 4px;\n",
       "  border-bottom: solid 1px var(--xr-border-color);\n",
       "}\n",
       "\n",
       ".xr-header > div,\n",
       ".xr-header > ul {\n",
       "  display: inline;\n",
       "  margin-top: 0;\n",
       "  margin-bottom: 0;\n",
       "}\n",
       "\n",
       ".xr-obj-type,\n",
       ".xr-array-name {\n",
       "  margin-left: 2px;\n",
       "  margin-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-obj-type {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-sections {\n",
       "  padding-left: 0 !important;\n",
       "  display: grid;\n",
       "  grid-template-columns: 150px auto auto 1fr 0 20px 0 20px;\n",
       "}\n",
       "\n",
       ".xr-section-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-section-item input {\n",
       "  display: inline-block;\n",
       "  opacity: 0;\n",
       "  height: 0;\n",
       "}\n",
       "\n",
       ".xr-section-item input + label {\n",
       "  color: var(--xr-disabled-color);\n",
       "  border: 2px solid transparent !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label {\n",
       "  cursor: pointer;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-item input:focus + label {\n",
       "  border: 2px solid var(--xr-font-color0) !important;\n",
       "}\n",
       "\n",
       ".xr-section-item input:enabled + label:hover {\n",
       "  color: var(--xr-font-color0);\n",
       "}\n",
       "\n",
       ".xr-section-summary {\n",
       "  grid-column: 1;\n",
       "  color: var(--xr-font-color2);\n",
       "  font-weight: 500;\n",
       "}\n",
       "\n",
       ".xr-section-summary > span {\n",
       "  display: inline-block;\n",
       "  padding-left: 0.5em;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label {\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in + label:before {\n",
       "  display: inline-block;\n",
       "  content: \"►\";\n",
       "  font-size: 11px;\n",
       "  width: 15px;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:disabled + label:before {\n",
       "  color: var(--xr-disabled-color);\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label:before {\n",
       "  content: \"▼\";\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked + label > span {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-section-summary,\n",
       ".xr-section-inline-details {\n",
       "  padding-top: 4px;\n",
       "  padding-bottom: 4px;\n",
       "}\n",
       "\n",
       ".xr-section-inline-details {\n",
       "  grid-column: 2 / -1;\n",
       "}\n",
       "\n",
       ".xr-section-details {\n",
       "  display: none;\n",
       "  grid-column: 1 / -1;\n",
       "  margin-bottom: 5px;\n",
       "}\n",
       "\n",
       ".xr-section-summary-in:checked ~ .xr-section-details {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-array-wrap {\n",
       "  grid-column: 1 / -1;\n",
       "  display: grid;\n",
       "  grid-template-columns: 20px auto;\n",
       "}\n",
       "\n",
       ".xr-array-wrap > label {\n",
       "  grid-column: 1;\n",
       "  vertical-align: top;\n",
       "}\n",
       "\n",
       ".xr-preview {\n",
       "  color: var(--xr-font-color3);\n",
       "}\n",
       "\n",
       ".xr-array-preview,\n",
       ".xr-array-data {\n",
       "  padding: 0 5px !important;\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-array-data,\n",
       ".xr-array-in:checked ~ .xr-array-preview {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       ".xr-array-in:checked ~ .xr-array-data,\n",
       ".xr-array-preview {\n",
       "  display: inline-block;\n",
       "}\n",
       "\n",
       ".xr-dim-list {\n",
       "  display: inline-block !important;\n",
       "  list-style: none;\n",
       "  padding: 0 !important;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list li {\n",
       "  display: inline-block;\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "}\n",
       "\n",
       ".xr-dim-list:before {\n",
       "  content: \"(\";\n",
       "}\n",
       "\n",
       ".xr-dim-list:after {\n",
       "  content: \")\";\n",
       "}\n",
       "\n",
       ".xr-dim-list li:not(:last-child):after {\n",
       "  content: \",\";\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-has-index {\n",
       "  font-weight: bold;\n",
       "}\n",
       "\n",
       ".xr-var-list,\n",
       ".xr-var-item {\n",
       "  display: contents;\n",
       "}\n",
       "\n",
       ".xr-var-item > div,\n",
       ".xr-var-item label,\n",
       ".xr-var-item > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-even);\n",
       "  border-color: var(--xr-background-color-row-odd);\n",
       "  margin-bottom: 0;\n",
       "  padding-top: 2px;\n",
       "}\n",
       "\n",
       ".xr-var-item > .xr-var-name:hover span {\n",
       "  padding-right: 5px;\n",
       "}\n",
       "\n",
       ".xr-var-list > li:nth-child(odd) > div,\n",
       ".xr-var-list > li:nth-child(odd) > label,\n",
       ".xr-var-list > li:nth-child(odd) > .xr-var-name span {\n",
       "  background-color: var(--xr-background-color-row-odd);\n",
       "  border-color: var(--xr-background-color-row-even);\n",
       "}\n",
       "\n",
       ".xr-var-name {\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-var-dims {\n",
       "  grid-column: 2;\n",
       "}\n",
       "\n",
       ".xr-var-dtype {\n",
       "  grid-column: 3;\n",
       "  text-align: right;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-preview {\n",
       "  grid-column: 4;\n",
       "}\n",
       "\n",
       ".xr-index-preview {\n",
       "  grid-column: 2 / 5;\n",
       "  color: var(--xr-font-color2);\n",
       "}\n",
       "\n",
       ".xr-var-name,\n",
       ".xr-var-dims,\n",
       ".xr-var-dtype,\n",
       ".xr-preview,\n",
       ".xr-attrs dt {\n",
       "  white-space: nowrap;\n",
       "  overflow: hidden;\n",
       "  text-overflow: ellipsis;\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-var-name:hover,\n",
       ".xr-var-dims:hover,\n",
       ".xr-var-dtype:hover,\n",
       ".xr-attrs dt:hover {\n",
       "  overflow: visible;\n",
       "  width: auto;\n",
       "  z-index: 1;\n",
       "}\n",
       "\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  display: none;\n",
       "  border-top: 2px dotted var(--xr-background-color);\n",
       "  padding-bottom: 20px !important;\n",
       "  padding-top: 10px !important;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in + label,\n",
       ".xr-var-data-in + label,\n",
       ".xr-index-data-in + label {\n",
       "  padding: 0 1px;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked ~ .xr-var-attrs,\n",
       ".xr-var-data-in:checked ~ .xr-var-data,\n",
       ".xr-index-data-in:checked ~ .xr-index-data {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       ".xr-var-data > table {\n",
       "  float: right;\n",
       "}\n",
       "\n",
       ".xr-var-data > pre,\n",
       ".xr-index-data > pre,\n",
       ".xr-var-data > table > tbody > tr {\n",
       "  background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".xr-var-name span,\n",
       ".xr-var-data,\n",
       ".xr-index-name div,\n",
       ".xr-index-data,\n",
       ".xr-attrs {\n",
       "  padding-left: 25px !important;\n",
       "}\n",
       "\n",
       ".xr-attrs,\n",
       ".xr-var-attrs,\n",
       ".xr-var-data,\n",
       ".xr-index-data {\n",
       "  grid-column: 1 / -1;\n",
       "}\n",
       "\n",
       "dl.xr-attrs {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  display: grid;\n",
       "  grid-template-columns: 125px auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt,\n",
       ".xr-attrs dd {\n",
       "  padding: 0;\n",
       "  margin: 0;\n",
       "  float: left;\n",
       "  padding-right: 10px;\n",
       "  width: auto;\n",
       "}\n",
       "\n",
       ".xr-attrs dt {\n",
       "  font-weight: normal;\n",
       "  grid-column: 1;\n",
       "}\n",
       "\n",
       ".xr-attrs dt:hover span {\n",
       "  display: inline-block;\n",
       "  background: var(--xr-background-color);\n",
       "  padding-right: 10px;\n",
       "}\n",
       "\n",
       ".xr-attrs dd {\n",
       "  grid-column: 2;\n",
       "  white-space: pre-wrap;\n",
       "  word-break: break-all;\n",
       "}\n",
       "\n",
       ".xr-icon-database,\n",
       ".xr-icon-file-text2,\n",
       ".xr-no-icon {\n",
       "  display: inline-block;\n",
       "  vertical-align: middle;\n",
       "  width: 1em;\n",
       "  height: 1.5em !important;\n",
       "  stroke-width: 0;\n",
       "  stroke: currentColor;\n",
       "  fill: currentColor;\n",
       "}\n",
       "\n",
       ".xr-var-attrs-in:checked + label > .xr-icon-file-text2,\n",
       ".xr-var-data-in:checked + label > .xr-icon-database,\n",
       ".xr-index-data-in:checked + label > .xr-icon-database {\n",
       "  color: var(--xr-font-color0);\n",
       "  filter: drop-shadow(1px 1px 5px var(--xr-font-color2));\n",
       "  stroke-width: 0.8px;\n",
       "}\n",
       "</style><pre class='xr-text-repr-fallback'>&lt;xarray.DataArray &#x27;insar_deformation&#x27; (time: 156, y: 2939, x: 3713)&gt; Size: 7GB\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1kB 2017-06-10 2017-06-22 ... 2022-10-18\n",
       "  * y        (y) int32 12kB 0 1 2 3 4 5 6 ... 2932 2933 2934 2935 2936 2937 2938\n",
       "  * x        (x) int32 15kB 0 1 2 3 4 5 6 ... 3706 3707 3708 3709 3710 3711 3712</pre><div class='xr-wrap' style='display:none'><div class='xr-header'><div class='xr-obj-type'>xarray.DataArray</div><div class='xr-array-name'>'insar_deformation'</div><ul class='xr-dim-list'><li><span class='xr-has-index'>time</span>: 156</li><li><span class='xr-has-index'>y</span>: 2939</li><li><span class='xr-has-index'>x</span>: 3713</li></ul></div><ul class='xr-sections'><li class='xr-section-item'><div class='xr-array-wrap'><input id='section-5a352688-5471-42e0-9ecb-fad1cce704bb' class='xr-array-in' type='checkbox' checked><label for='section-5a352688-5471-42e0-9ecb-fad1cce704bb' title='Show/hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-array-preview xr-preview'><span>0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0 ... 0.0 0.0 0.0 0.0 0.0 0.0 0.0 0.0</span></div><div class='xr-array-data'><pre>array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)</pre></div></div></li><li class='xr-section-item'><input id='section-6a67c4d9-f3bb-45cf-ad02-fa6d74ad7cda' class='xr-section-summary-in' type='checkbox'  checked><label for='section-6a67c4d9-f3bb-45cf-ad02-fa6d74ad7cda' class='xr-section-summary' >Coordinates: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>time</span></div><div class='xr-var-dims'>(time)</div><div class='xr-var-dtype'>datetime64[ns]</div><div class='xr-var-preview xr-preview'>2017-06-10 ... 2022-10-18</div><input id='attrs-9a371edb-f582-48df-9922-3ff77fd125f3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-9a371edb-f582-48df-9922-3ff77fd125f3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-cbdceec3-8275-4ac3-a93c-5734a6c66e53' class='xr-var-data-in' type='checkbox'><label for='data-cbdceec3-8275-4ac3-a93c-5734a6c66e53' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([&#x27;2017-06-10T00:00:00.000000000&#x27;, &#x27;2017-06-22T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-07-04T00:00:00.000000000&#x27;, &#x27;2017-07-16T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-07-28T00:00:00.000000000&#x27;, &#x27;2017-08-09T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-08-21T00:00:00.000000000&#x27;, &#x27;2017-10-08T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-10-20T00:00:00.000000000&#x27;, &#x27;2017-11-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-11-13T00:00:00.000000000&#x27;, &#x27;2017-11-25T00:00:00.000000000&#x27;,\n",
       "       &#x27;2017-12-07T00:00:00.000000000&#x27;, &#x27;2017-12-19T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-01-12T00:00:00.000000000&#x27;, &#x27;2018-01-24T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-02-05T00:00:00.000000000&#x27;, &#x27;2018-03-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-03-13T00:00:00.000000000&#x27;, &#x27;2018-03-25T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-04-06T00:00:00.000000000&#x27;, &#x27;2018-04-18T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-04-30T00:00:00.000000000&#x27;, &#x27;2018-05-12T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-05-24T00:00:00.000000000&#x27;, &#x27;2018-06-05T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-06-17T00:00:00.000000000&#x27;, &#x27;2018-06-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-07-11T00:00:00.000000000&#x27;, &#x27;2018-07-23T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-07-29T00:00:00.000000000&#x27;, &#x27;2018-08-04T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-08-10T00:00:00.000000000&#x27;, &#x27;2018-08-16T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-08-22T00:00:00.000000000&#x27;, &#x27;2018-08-28T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-09-03T00:00:00.000000000&#x27;, &#x27;2018-09-09T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-09-21T00:00:00.000000000&#x27;, &#x27;2018-10-03T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-10-15T00:00:00.000000000&#x27;, &#x27;2018-11-20T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-12-02T00:00:00.000000000&#x27;, &#x27;2018-12-14T00:00:00.000000000&#x27;,\n",
       "       &#x27;2018-12-26T00:00:00.000000000&#x27;, &#x27;2019-02-12T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-02-24T00:00:00.000000000&#x27;, &#x27;2019-04-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-04-13T00:00:00.000000000&#x27;, &#x27;2019-04-25T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-05-07T00:00:00.000000000&#x27;, &#x27;2019-05-19T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-05-25T00:00:00.000000000&#x27;, &#x27;2019-05-31T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-06-06T00:00:00.000000000&#x27;, &#x27;2019-06-18T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-06-24T00:00:00.000000000&#x27;, &#x27;2019-07-06T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-07-12T00:00:00.000000000&#x27;, &#x27;2019-07-18T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-07-24T00:00:00.000000000&#x27;, &#x27;2019-07-30T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-08-11T00:00:00.000000000&#x27;, &#x27;2019-08-17T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-08-23T00:00:00.000000000&#x27;, &#x27;2019-08-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-09-04T00:00:00.000000000&#x27;, &#x27;2019-09-10T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-09-16T00:00:00.000000000&#x27;, &#x27;2019-09-22T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-09-28T00:00:00.000000000&#x27;, &#x27;2019-10-04T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-10-10T00:00:00.000000000&#x27;, &#x27;2019-10-16T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-10-22T00:00:00.000000000&#x27;, &#x27;2019-10-28T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-11-03T00:00:00.000000000&#x27;, &#x27;2019-11-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-11-27T00:00:00.000000000&#x27;, &#x27;2019-12-09T00:00:00.000000000&#x27;,\n",
       "       &#x27;2019-12-21T00:00:00.000000000&#x27;, &#x27;2020-01-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-01-26T00:00:00.000000000&#x27;, &#x27;2020-02-07T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-02-19T00:00:00.000000000&#x27;, &#x27;2020-03-14T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-04-07T00:00:00.000000000&#x27;, &#x27;2020-05-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-05-13T00:00:00.000000000&#x27;, &#x27;2020-05-19T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-05-25T00:00:00.000000000&#x27;, &#x27;2020-05-31T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-06-06T00:00:00.000000000&#x27;, &#x27;2020-06-12T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-06-18T00:00:00.000000000&#x27;, &#x27;2020-06-24T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-06-30T00:00:00.000000000&#x27;, &#x27;2020-08-05T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-08-11T00:00:00.000000000&#x27;, &#x27;2020-08-17T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-08-23T00:00:00.000000000&#x27;, &#x27;2020-08-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-09-04T00:00:00.000000000&#x27;, &#x27;2020-09-10T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-09-16T00:00:00.000000000&#x27;, &#x27;2020-09-22T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-09-28T00:00:00.000000000&#x27;, &#x27;2020-10-04T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-10T00:00:00.000000000&#x27;, &#x27;2020-10-16T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-10-28T00:00:00.000000000&#x27;, &#x27;2020-11-03T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-11-09T00:00:00.000000000&#x27;, &#x27;2020-11-21T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-12-03T00:00:00.000000000&#x27;, &#x27;2020-12-15T00:00:00.000000000&#x27;,\n",
       "       &#x27;2020-12-27T00:00:00.000000000&#x27;, &#x27;2021-04-02T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-04-14T00:00:00.000000000&#x27;, &#x27;2021-05-08T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-05-26T00:00:00.000000000&#x27;, &#x27;2021-06-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-06-25T00:00:00.000000000&#x27;, &#x27;2021-07-01T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-07-07T00:00:00.000000000&#x27;, &#x27;2021-07-13T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-07-19T00:00:00.000000000&#x27;, &#x27;2021-07-25T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-07-31T00:00:00.000000000&#x27;, &#x27;2021-08-12T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-08-18T00:00:00.000000000&#x27;, &#x27;2021-08-24T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-08-30T00:00:00.000000000&#x27;, &#x27;2021-09-05T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-09-11T00:00:00.000000000&#x27;, &#x27;2021-09-17T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-09-23T00:00:00.000000000&#x27;, &#x27;2021-09-29T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-10-05T00:00:00.000000000&#x27;, &#x27;2021-10-11T00:00:00.000000000&#x27;,\n",
       "       &#x27;2021-12-10T00:00:00.000000000&#x27;, &#x27;2021-12-22T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-01-03T00:00:00.000000000&#x27;, &#x27;2022-02-08T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-03-04T00:00:00.000000000&#x27;, &#x27;2022-03-28T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-04-09T00:00:00.000000000&#x27;, &#x27;2022-04-21T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-06-08T00:00:00.000000000&#x27;, &#x27;2022-06-20T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-07-02T00:00:00.000000000&#x27;, &#x27;2022-07-14T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-07-26T00:00:00.000000000&#x27;, &#x27;2022-09-12T00:00:00.000000000&#x27;,\n",
       "       &#x27;2022-10-06T00:00:00.000000000&#x27;, &#x27;2022-10-18T00:00:00.000000000&#x27;],\n",
       "      dtype=&#x27;datetime64[ns]&#x27;)</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>y</span></div><div class='xr-var-dims'>(y)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 ... 2935 2936 2937 2938</div><input id='attrs-c131c608-8b1d-42e0-9ac8-f48bd8b96fb3' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-c131c608-8b1d-42e0-9ac8-f48bd8b96fb3' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-c4c5e642-1cb8-4afc-9d95-02a5630b2278' class='xr-var-data-in' type='checkbox'><label for='data-c4c5e642-1cb8-4afc-9d95-02a5630b2278' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([   0,    1,    2, ..., 2936, 2937, 2938])</pre></div></li><li class='xr-var-item'><div class='xr-var-name'><span class='xr-has-index'>x</span></div><div class='xr-var-dims'>(x)</div><div class='xr-var-dtype'>int32</div><div class='xr-var-preview xr-preview'>0 1 2 3 4 ... 3709 3710 3711 3712</div><input id='attrs-aaafce48-c703-46f3-9e2f-4e830985fcda' class='xr-var-attrs-in' type='checkbox' disabled><label for='attrs-aaafce48-c703-46f3-9e2f-4e830985fcda' title='Show/Hide attributes'><svg class='icon xr-icon-file-text2'><use xlink:href='#icon-file-text2'></use></svg></label><input id='data-253581e9-09d3-403c-82b8-962a1f4bedd1' class='xr-var-data-in' type='checkbox'><label for='data-253581e9-09d3-403c-82b8-962a1f4bedd1' title='Show/Hide data repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-var-attrs'><dl class='xr-attrs'></dl></div><div class='xr-var-data'><pre>array([   0,    1,    2, ..., 3710, 3711, 3712])</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-585e1f0d-4fad-46d1-b50d-f25d383f8fad' class='xr-section-summary-in' type='checkbox'  ><label for='section-585e1f0d-4fad-46d1-b50d-f25d383f8fad' class='xr-section-summary' >Indexes: <span>(3)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><ul class='xr-var-list'><li class='xr-var-item'><div class='xr-index-name'><div>time</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-a82b4ed0-a32e-451e-b74c-aac85abe29e8' class='xr-index-data-in' type='checkbox'/><label for='index-a82b4ed0-a32e-451e-b74c-aac85abe29e8' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(DatetimeIndex([&#x27;2017-06-10&#x27;, &#x27;2017-06-22&#x27;, &#x27;2017-07-04&#x27;, &#x27;2017-07-16&#x27;,\n",
       "               &#x27;2017-07-28&#x27;, &#x27;2017-08-09&#x27;, &#x27;2017-08-21&#x27;, &#x27;2017-10-08&#x27;,\n",
       "               &#x27;2017-10-20&#x27;, &#x27;2017-11-01&#x27;,\n",
       "               ...\n",
       "               &#x27;2022-04-09&#x27;, &#x27;2022-04-21&#x27;, &#x27;2022-06-08&#x27;, &#x27;2022-06-20&#x27;,\n",
       "               &#x27;2022-07-02&#x27;, &#x27;2022-07-14&#x27;, &#x27;2022-07-26&#x27;, &#x27;2022-09-12&#x27;,\n",
       "               &#x27;2022-10-06&#x27;, &#x27;2022-10-18&#x27;],\n",
       "              dtype=&#x27;datetime64[ns]&#x27;, name=&#x27;time&#x27;, length=156, freq=None))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>y</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-beddf3f7-e31a-4e0a-a8ab-d44b1899057a' class='xr-index-data-in' type='checkbox'/><label for='index-beddf3f7-e31a-4e0a-a8ab-d44b1899057a' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "       ...\n",
       "       2929, 2930, 2931, 2932, 2933, 2934, 2935, 2936, 2937, 2938],\n",
       "      dtype=&#x27;int32&#x27;, name=&#x27;y&#x27;, length=2939))</pre></div></li><li class='xr-var-item'><div class='xr-index-name'><div>x</div></div><div class='xr-index-preview'>PandasIndex</div><input type='checkbox' disabled/><label></label><input id='index-7fceab94-0a68-4534-8ca9-03725f2f3f3e' class='xr-index-data-in' type='checkbox'/><label for='index-7fceab94-0a68-4534-8ca9-03725f2f3f3e' title='Show/Hide index repr'><svg class='icon xr-icon-database'><use xlink:href='#icon-database'></use></svg></label><div class='xr-index-data'><pre>PandasIndex(Index([   0,    1,    2,    3,    4,    5,    6,    7,    8,    9,\n",
       "       ...\n",
       "       3703, 3704, 3705, 3706, 3707, 3708, 3709, 3710, 3711, 3712],\n",
       "      dtype=&#x27;int32&#x27;, name=&#x27;x&#x27;, length=3713))</pre></div></li></ul></div></li><li class='xr-section-item'><input id='section-9629f029-7a93-4473-bb36-4803b1c8df63' class='xr-section-summary-in' type='checkbox' disabled ><label for='section-9629f029-7a93-4473-bb36-4803b1c8df63' class='xr-section-summary'  title='Expand/collapse section'>Attributes: <span>(0)</span></label><div class='xr-section-inline-details'></div><div class='xr-section-details'><dl class='xr-attrs'></dl></div></li></ul></div></div>"
      ],
      "text/plain": [
       "<xarray.DataArray 'insar_deformation' (time: 156, y: 2939, x: 3713)> Size: 7GB\n",
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "...\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]],\n",
       "\n",
       "       [[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.]]], dtype=float32)\n",
       "Coordinates:\n",
       "  * time     (time) datetime64[ns] 1kB 2017-06-10 2017-06-22 ... 2022-10-18\n",
       "  * y        (y) int32 12kB 0 1 2 3 4 5 6 ... 2932 2933 2934 2935 2936 2937 2938\n",
       "  * x        (x) int32 15kB 0 1 2 3 4 5 6 ... 3706 3707 3708 3709 3710 3711 3712"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "insar_da = load_insar_h5_as_xarray(INSAR_H5)\n",
    "insar_da\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d863463c",
   "metadata": {},
   "source": [
    "# 3) Inspect W3RA NetCDFs and pick variable names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5dec1d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- W3RA_2010_2024_.nc ---\n",
      "vars: ['S0_EU_2010', 'Sd_EU_2010', 'Sg_EU_2010', 'Sr_EU_2010', 'Ss_EU_2010', 'Ssnow_EU_2010', 'Stot_EU_2010', 'S0_EU_2011', 'Sd_EU_2011', 'Sg_EU_2011']\n",
      "dims: {'lat': 22, 'lon': 24, 'time_2010': 365, 'time_2011': 365, 'time_2012': 366, 'time_2013': 365, 'time_2014': 365, 'time_2015': 365, 'time_2016': 366, 'time_2017': 365, 'time_2018': 365, 'time_2019': 365, 'time_2020': 366, 'time_2021': 365, 'time_2022': 365, 'time_2023': 365, 'time_2024': 213}\n",
      "\n",
      "--- W3RA_2010_2024.nc ---\n",
      "vars: []\n",
      "dims: {'lat': 22, 'lon': 24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JR80FD\\AppData\\Local\\Temp\\ipykernel_16316\\4106634407.py:11: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(\"dims:\", dict(ds.dims))\n",
      "C:\\Users\\JR80FD\\AppData\\Local\\Temp\\ipykernel_16316\\4106634407.py:11: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(\"dims:\", dict(ds.dims))\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "for name in [\"W3RA_2010_2024_.nc\", \"W3RA_2010_2024.nc\"]:\n",
    "    p = W3RA_DIR / name\n",
    "    try:\n",
    "        ds = xr.open_dataset(p)\n",
    "        print(\"\\n---\", name, \"---\")\n",
    "        print(\"vars:\", list(ds.data_vars)[:10])\n",
    "        print(\"dims:\", dict(ds.dims))\n",
    "        if \"time\" in ds:\n",
    "            print(\"time:\", str(ds.time.values[:3]), \"…\", str(ds.time.values[-3:]), f\"({ds.dims['time']} steps)\")\n",
    "        ds.close()\n",
    "    except Exception as e:\n",
    "        print(\"\\n---\", name, \"---\\n\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c3595d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "picked: {'Sg': 'Sg_EU_2024', 'Sd': 'Sd_EU_2024', 'S0': 'S0_EU_2024'}\n",
      "(213, 22, 24) (213, 22, 24) (213, 22, 24) ('time_2024', 'lat', 'lon')\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(W3RA_DIR / \"W3RA_2010_2024_.nc\")\n",
    "# Adjust names if different in your file:\n",
    "name_map = {\"Sg\":\"Sg\", \"Sd\":\"Sd\", \"S0\":\"S0\"}\n",
    "for k in list(ds.data_vars):\n",
    "    kl = k.lower()\n",
    "    if \"sg\" in kl: name_map[\"Sg\"] = k\n",
    "    if \"sd\" in kl: name_map[\"Sd\"] = k\n",
    "    if \"s0\" in kl or \"stot0\" in kl: name_map[\"S0\"] = k\n",
    "\n",
    "sg_all = ds[name_map[\"Sg\"]]\n",
    "sd_all = ds[name_map[\"Sd\"]]\n",
    "s0_all = ds[name_map[\"S0\"]]\n",
    "print(\"picked:\", name_map)\n",
    "print(sg_all.shape, sd_all.shape, s0_all.shape, sg_all.dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4d2529",
   "metadata": {},
   "source": [
    "Stitch W3RA years into continuous time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffae9b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "def stitch_years(ds, base_prefix):\n",
    "    \"\"\"\n",
    "    Collect variables like f'{base_prefix}_{YYYY}' each with dim 'time_YYYY',\n",
    "    rename that dim to 'time', cast to datetime, then concat over time.\n",
    "    Returns a single DataArray with dims (time, lat, lon).\n",
    "    \"\"\"\n",
    "    pats = []\n",
    "    for k in ds.data_vars:\n",
    "        m = re.fullmatch(fr\"{re.escape(base_prefix)}_(\\d{{4}})\", k)\n",
    "        if m: pats.append((int(m.group(1)), k))\n",
    "    if not pats:\n",
    "        raise ValueError(f\"No yearly vars found for prefix {base_prefix}\")\n",
    "    pats.sort()  # by year\n",
    "    chunks = []\n",
    "    for year, var in pats:\n",
    "        da = ds[var]\n",
    "        time_dim = f\"time_{year}\"\n",
    "        if time_dim not in da.dims:\n",
    "            raise ValueError(f\"{var} missing dim {time_dim}\")\n",
    "        da = da.rename({time_dim: \"time\"})\n",
    "        # ensure datetime64\n",
    "        da = da.assign_coords(time=pd.to_datetime(da['time'].values))\n",
    "        chunks.append(da)\n",
    "    out = xr.concat(chunks, dim=\"time\")\n",
    "    return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2154140d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5326, 22, 24) (5326, 22, 24) (5326, 22, 24) ('time', 'lat', 'lon')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sg_all = stitch_years(ds, \"Sg_EU\")\n",
    "sd_all = stitch_years(ds, \"Sd_EU\")\n",
    "s0_all = stitch_years(ds, \"S0_EU\")\n",
    "print(sg_all.shape, sd_all.shape, s0_all.shape, sg_all.dims)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bf57cf",
   "metadata": {},
   "source": [
    "# 4) Align the time window to your InSAR \n",
    "(2017-06-10 → 2022-10-18) and monthly resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d1470ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W3RA monthly shapes: (65, 22, 24) (65, 22, 24) (65, 22, 24)\n"
     ]
    }
   ],
   "source": [
    "# InSAR time range from your HDF5 summary:\n",
    "tmin_insar = pd.Timestamp(\"2017-06-01\")   # round to month for resample\n",
    "tmax_insar = pd.Timestamp(\"2022-10-31\")\n",
    "\n",
    "# Monthly means\n",
    "sg_m = sg_all.resample(time=\"MS\").mean()\n",
    "sd_m = sd_all.resample(time=\"MS\").mean()\n",
    "s0_m = s0_all.resample(time=\"MS\").mean()\n",
    "\n",
    "# Subset to common window\n",
    "sg_m = sg_m.sel(time=slice(tmin_insar, tmax_insar))\n",
    "sd_m = sd_m.sel(time=slice(tmin_insar, tmax_insar))\n",
    "s0_m = s0_m.sel(time=slice(tmin_insar, tmax_insar))\n",
    "print(\"W3RA monthly shapes:\", sg_m.shape, sd_m.shape, s0_m.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3ea610",
   "metadata": {},
   "source": [
    "# 5) Build InSAR xarray with lat/lon from HDF5 attrs (1D grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5e1b3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSAR monthly shape: (65, 2939, 3713)\n"
     ]
    }
   ],
   "source": [
    "import h5py, numpy as np, xarray as xr, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "with h5py.File(INSAR_H5, \"r\") as f:\n",
    "    ts = f[\"timeseries\"][:]             # (T,H,W)\n",
    "    raw_dates = [d.decode() for d in f[\"date\"][:]]\n",
    "    time = pd.to_datetime(raw_dates, format=\"%Y%m%d\")\n",
    "    attrs = f[\"timeseries\"].attrs\n",
    "    X_FIRST = attrs.get(\"X_FIRST\", None)\n",
    "    Y_FIRST = attrs.get(\"Y_FIRST\", None)\n",
    "    X_STEP  = attrs.get(\"X_STEP\",  None)\n",
    "    Y_STEP  = attrs.get(\"Y_STEP\",  None)\n",
    "\n",
    "T,H,W = ts.shape\n",
    "insar_da = xr.DataArray(ts, dims=(\"time\",\"y\",\"x\"),\n",
    "                        coords={\"time\": time,\n",
    "                                \"y\": np.arange(H),\n",
    "                                \"x\": np.arange(W)},\n",
    "                        name=\"insar_deformation\")\n",
    "\n",
    "# If geocoded attrs are present, add lon/lat 1D coords\n",
    "if None not in (X_FIRST, X_STEP, Y_FIRST, Y_STEP):\n",
    "    lon_1d = X_FIRST + np.arange(W) * X_STEP\n",
    "    lat_1d = Y_FIRST + np.arange(H) * Y_STEP\n",
    "    insar_da = insar_da.assign_coords(lon=(\"x\", lon_1d), lat=(\"y\", lat_1d))\n",
    "\n",
    "# Resample to monthly means and subset\n",
    "insar_m = insar_da.resample(time=\"MS\").mean().sel(time=slice(tmin_insar, tmax_insar))\n",
    "print(\"InSAR monthly shape:\", insar_m.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20528ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-level datasets: ['bperp', 'date', 'timeseries']\n",
      "attrs: {'ALOOKS': '4', 'ANTENNA_SIDE': '-1', 'AZIMUTH_PIXEL_SIZE': '56.4', 'BANDS': '1', 'CENTER_LINE_UTC': '19151.797495', 'DATA_TYPE': 'float32', 'DATE12': '170610-170622', 'EARTH_RADIUS': '6367896.9087', 'END_DATE': '20221018', 'EPSG': '32633', 'FILE_LENGTH': '2945', 'FILE_PATH': '/mnt/data/aoi_3_02_bologna/MintPy/timeseries_ERA5_ramp_demErr.h5', 'FILE_TYPE': 'timeseries', 'HEADING': '-165.9793419', 'HEIGHT': '701867.9117', 'INTERLEAVE': 'BSQ', 'LAT_REF1': '5011480.0', 'LAT_REF2': '5011480.0', 'LAT_REF3': '4775880.0', 'LAT_REF4': '4775880.0', 'LENGTH': '2939', 'LON_REF1': '413880.0', 'LON_REF2': '116360.0', 'LON_REF3': '413880.0', 'LON_REF4': '116360.0', 'NO_DATA_VALUE': '0.0', 'NoDataValue': '0.0', 'ORBIT_DIRECTION': 'DESCENDING', 'PLATFORM': 'Sen', 'PROCESSOR': 'hyp3', 'PROJECT_NAME': 'mintpy_config', 'P_BASELINE_BOTTOM_HDR': '-3.725', 'P_BASELINE_TOP_HDR': '-3.725', 'RANGE_PIXEL_SIZE': '46.0', 'REF_DATE': '20220103', 'REF_LAT': '4935120.0', 'REF_LON': '233520.0', 'REF_X': '1464', 'REF_Y': '954', 'RLOOKS': '20', 'STARTING_RANGE': '799900.8131', 'START_DATE': '20170610', 'SUBSET_XMAX': '3713', 'SUBSET_XMIN': '0', 'SUBSET_YMAX': '2939', 'SUBSET_YMIN': '0', 'UNIT': 'm', 'UTM_ZONE': '33N', 'WAVELENGTH': '0.055465764662349676', 'WIDTH': '3713', 'XMAX': '3712', 'X_FIRST': '116360.0', 'X_STEP': '80.0', 'X_UNIT': 'meters', 'YMAX': '2938', 'Y_FIRST': '5011480.0', 'Y_STEP': '-80.0', 'Y_UNIT': 'meters', 'beam_mode': 'IW', 'beam_swath': '123', 'mintpy.compute.cluster': 'local', 'mintpy.compute.memory': 'auto', 'mintpy.compute.numWorker': '64', 'mintpy.deramp': 'quadratic', 'mintpy.deramp.maskFile': 'maskTempCoh.h5', 'mintpy.load.azAngleFile': '/mnt/data/aoi_3_02_bologna/*/*_lv_phi*.tif', 'mintpy.load.corFile': '/mnt/data/aoi_3_02_bologna/*/*_corr*.tif', 'mintpy.load.demFile': '/mnt/data/aoi_3_02_bologna/*/*_dem*.tif', 'mintpy.load.incAngleFile': '/mnt/data/aoi_3_02_bologna/*/*_lv_theta*.tif', 'mintpy.load.processor': 'hyp3', 'mintpy.load.unwFile': '/mnt/data/aoi_3_02_bologna/*/*_unw_phase*.tif', 'mintpy.load.waterMaskFile': '/mnt/data/aoi_3_02_bologna/*/*_water_mask*.tif', 'mintpy.network.maxPerpBaseline': '100', 'mintpy.network.maxTempBaseline': '60', 'mintpy.networkInversion.maskDataset': 'False', 'mintpy.networkInversion.maskThreshold': '0.4', 'mintpy.networkInversion.minNormVelocity': 'True', 'mintpy.networkInversion.minRedundancy': '1.0', 'mintpy.networkInversion.numIfgram': '163', 'mintpy.networkInversion.obsDatasetName': 'unwrapPhase', 'mintpy.networkInversion.weightFunc': 'var', 'mintpy.reference.interpMethod': 'linear', 'mintpy.reference.lalo': '44.5199558120, 11.6468120447', 'mintpy.reference.pixelMethod': 'lonlat', 'mintpy.subset.lalo': 'auto', 'mintpy.subset.yx': '0:2939,0:3713', 'mintpy.tempCohMask.min': '0.4', 'mintpy.topographicResidual.excludeDate': \"['exclude_date.txt']\", 'mintpy.topographicResidual.phaseVelocity': 'False', 'mintpy.topographicResidual.polyOrder': '2', 'mintpy.topographicResidual.stepDate': '[]', 'mintpy.troposphericDelay.method': 'weathermodel', 'mintpy.unwrapMask.connCompMinPix': '100', 'mintpy.unwrapMask.maskFile': 'auto', 'mintpy.waterBody.mask': 'auto', 'mintpy.weatherModel.heightRef': 'auto', 'mintpy.weatherModel.weatherDir': '/mnt/data/aoi_3_bologna_weather', 'mintpy.weatherModel.weatherFile': 'era5_tcwv_*.nc', 'mintpy.weatherModel.weatherModel': 'ERA5', 'mintpy.workDir': '/mnt/data/aoi_3_02_bologna/mintpy', 'relative_orbit': '95', 'startUTC': '2017-06-10 05:19:09.000000', 'stopUTC': '2017-06-10 05:19:36.000000', 'unwrap_method': 'mcf'}\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "with h5py.File(INSAR_H5, \"r\") as g:\n",
    "    print(\"Top-level datasets:\", list(g.keys()))           # e.g., ['latitude','longitude',...]\n",
    "    for k in [\"latitude\",\"longitude\",\"y\",\"x\",\"azimuthCoord\",\"rangeCoord\"]:\n",
    "        if k in g:\n",
    "            print(k, g[k].shape, g[k].dtype)\n",
    "    # global attrs can carry projection info (EPSG/UTM zone)\n",
    "    print(\"attrs:\", {a: g.attrs[a] for a in g.attrs.keys()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c186bd80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "with h5py.File(INSAR_H5, \"r\") as f:\n",
    "    A = f[\"timeseries\"].attrs\n",
    "    print({k: A[k] for k in [\"EPSG\",\"X_FIRST\",\"X_STEP\",\"X_UNIT\",\"Y_FIRST\",\"Y_STEP\",\"Y_UNIT\"] if k in A})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5309c4cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSAR monthly: (65, 2939, 3713) | coords now: ['lat', 'lon']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "from pyproj import Transformer\n",
    "\n",
    "# ------------- get UTM grid from geometryGeo.h5 -------------\n",
    "geom_path = r\"C:\\Users\\JR80FD\\swin_test\\inputs\\geometryGeo.h5\"\n",
    "with h5py.File(geom_path, \"r\") as g:\n",
    "    EPSG = int(g.attrs.get(\"EPSG\", 32633))           # 32633 = UTM 33N\n",
    "    X_FIRST = float(g.attrs[\"X_FIRST\"])              # meters\n",
    "    X_STEP  = float(g.attrs[\"X_STEP\"])               # meters\n",
    "    Y_FIRST = float(g.attrs[\"Y_FIRST\"])              # meters\n",
    "    Y_STEP  = float(g.attrs[\"Y_STEP\"])               # meters\n",
    "\n",
    "H = insar_da.sizes[\"y\"]\n",
    "W = insar_da.sizes[\"x\"]\n",
    "\n",
    "# Easting/Northing 1D\n",
    "x_e = X_FIRST + np.arange(W) * X_STEP                # shape (W,)\n",
    "y_n = Y_FIRST + np.arange(H) * Y_STEP                # shape (H,)\n",
    "\n",
    "# 2D mesh in UTM\n",
    "XX, YY = np.meshgrid(x_e, y_n)                       # (H,W)\n",
    "\n",
    "# Transform UTM -> lon/lat\n",
    "to_ll = Transformer.from_crs(EPSG, 4326, always_xy=True)\n",
    "lon2d, lat2d = to_ll.transform(XX, YY)               # float64 arrays\n",
    "\n",
    "# keep memory sane\n",
    "lon2d = lon2d.astype(\"float32\")\n",
    "lat2d = lat2d.astype(\"float32\")\n",
    "\n",
    "# Attach as coords to your existing insar_da\n",
    "insar_da = insar_da.assign_coords(lat=((\"y\",\"x\"), lat2d),\n",
    "                                  lon=((\"y\",\"x\"), lon2d))\n",
    "\n",
    "# Monthly resample + subset (reuse your existing time window if you defined it)\n",
    "insar_m = insar_da.resample(time=\"MS\").mean()\n",
    "insar_m = insar_m.sel(time=slice(\"2017-06-01\", \"2022-10-31\"))\n",
    "\n",
    "print(\"InSAR monthly:\", insar_m.shape, \"| coords now:\", [c for c in insar_m.coords if c in (\"lat\",\"lon\")])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b3a673c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jr80fd\\swin_test\\timeseries_ERA5_ramp_demErr.h5\n"
     ]
    }
   ],
   "source": [
    "print(INSAR_H5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4bfba7",
   "metadata": {},
   "source": [
    "# 6) Interpolate W3RA → InSAR grid (bilinear)\n",
    "\n",
    "W3RA is daily (2010–2024).\n",
    "\n",
    "InSAR is irregular (6/12 days) but you resampled it to monthly means (156 steps for 2017–2022).\n",
    "Both datasets aligned as 4D tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "10087a57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regridded: (65, 2939, 3713) (65, 2939, 3713) (65, 2939, 3713)\n"
     ]
    }
   ],
   "source": [
    "# Time-align first\n",
    "insar_m, sg_m = xr.align(insar_m, sg_m, join=\"inner\")\n",
    "_, sd_m = xr.align(insar_m, sd_m, join=\"inner\")\n",
    "_, s0_m = xr.align(insar_m, s0_m, join=\"inner\")\n",
    "\n",
    "# Bilinear interpolation onto the 2D lon/lat of InSAR\n",
    "sg_on_insar = sg_m.interp(lat=insar_m[\"lat\"], lon=insar_m[\"lon\"], method=\"linear\")\n",
    "sd_on_insar = sd_m.interp(lat=insar_m[\"lat\"], lon=insar_m[\"lon\"], method=\"linear\")\n",
    "s0_on_insar = s0_m.interp(lat=insar_m[\"lat\"], lon=insar_m[\"lon\"], method=\"linear\")\n",
    "\n",
    "print(\"Regridded:\", sg_on_insar.shape, sd_on_insar.shape, s0_on_insar.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37199363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: C:\\Users\\jr80fd\\swin_test\\insar_aligned.nc C:\\Users\\jr80fd\\swin_test\\w3ra_aligned.nc\n"
     ]
    }
   ],
   "source": [
    "# Paths\n",
    "out_insar = BASE / \"insar_aligned.nc\"\n",
    "out_w3ra  = BASE / \"w3ra_aligned.nc\"\n",
    "\n",
    "# Save InSAR\n",
    "insar_m.to_netcdf(out_insar)\n",
    "\n",
    "# Combine W3RA (stack channels into one Dataset)\n",
    "xr.Dataset({\n",
    "    \"Sg\": sg_m,\n",
    "    \"Sd\": sd_m,\n",
    "    \"S0\": s0_m,\n",
    "}).to_netcdf(out_w3ra)\n",
    "\n",
    "print(\"Saved:\", out_insar, out_w3ra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69059e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(65, 2939, 3713) (65, 2939, 3713) (65, 2939, 3713) (65, 2939, 3713)\n",
      "True True True\n"
     ]
    }
   ],
   "source": [
    "print(insar_m.shape, sg_on_insar.shape, sd_on_insar.shape, s0_on_insar.shape)\n",
    "print(insar_m.time.equals(sg_on_insar.time),\n",
    "      insar_m.y.equals(sg_on_insar.y),\n",
    "      insar_m.x.equals(sg_on_insar.x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "144e8521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "InSAR NaN% = 15.384615384615385\n",
      "Sg NaN% = 50.910693573896445\n",
      "Sd NaN% = 50.910693573896445\n",
      "S0 NaN% = 50.910693573896445\n"
     ]
    }
   ],
   "source": [
    "for da,name in [(insar_m,\"InSAR\"),(sg_on_insar,\"Sg\"),(sd_on_insar,\"Sd\"),(s0_on_insar,\"S0\")]:\n",
    "    print(name, \"NaN% =\", float(da.isnull().mean().values)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "66e5c9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatetimeIndex([], dtype='datetime64[ns]', freq=None)\n"
     ]
    }
   ],
   "source": [
    "print(pd.Index(insar_m.time.values).difference(sg_on_insar.time.values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "847f6c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "center pixel: 0.01842602901160717 nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JR80FD\\.conda\\envs\\datasci_env\\lib\\site-packages\\numpy\\lib\\nanfunctions.py:1879: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    }
   ],
   "source": [
    "i,j = insar_m.sizes['y']//2, insar_m.sizes['x']//2\n",
    "print(\"center pixel:\", float(insar_m.isel(y=i,x=j).std()), \n",
    "      float(sg_on_insar.isel(y=i,x=j).std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "faf29f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat/lon @center: 44.820499420166016 12.223923683166504\n"
     ]
    }
   ],
   "source": [
    "lat,lon = float(insar_m.lat.isel(y=i,x=j)), float(insar_m.lon.isel(y=i,x=j))\n",
    "print(\"lat/lon @center:\", lat, lon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa16647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "out_insar = BASE / \"insar_aligned.nc\"\n",
    "out_w3ra  = BASE / \"w3ra_aligned.nc\"\n",
    "\n",
    "# Save InSAR\n",
    "insar_m.to_netcdf(out_insar)\n",
    "\n",
    "# Combine W3RA (stack channels into one Dataset)\n",
    "xr.Dataset({\n",
    "    \"Sg\": sg_m,\n",
    "    \"Sd\": sd_m,\n",
    "    \"S0\": s0_m,\n",
    "}).to_netcdf(out_w3ra)\n",
    "\n",
    "print(\"Saved:\", out_insar, out_w3ra)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6188412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, json, time\n",
    "from pathlib import Path\n",
    "\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SEED = 42\n",
    "torch.manual_seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "BASE = Path(BASE)  # <- respects your existing BASE (don’t overwrite)\n",
    "insar_nc = BASE / \"insar_aligned.nc\"\n",
    "w3ra_nc  = BASE / \"w3ra_aligned.nc\"\n",
    "\n",
    "assert insar_nc.exists() and w3ra_nc.exists(), \"NetCDF files not found.\"\n",
    "\n",
    "def find_single_datavar(ds: xr.Dataset):\n",
    "    # return the only/first data variable name\n",
    "    vars_ = list(ds.data_vars)\n",
    "    if not vars_:\n",
    "        raise ValueError(\"No data variables in Dataset.\")\n",
    "    # prefer common names if present\n",
    "    for k in [\"uz\",\"u\",\"defo\",\"disp\",\"unw\",\"vel\",\"def\"]:\n",
    "        if k in vars_:\n",
    "            return k\n",
    "    return vars_[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6d1e0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you ever did f = h5py.File(...), make sure it's closed\n",
    "try:\n",
    "    f.close()\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d545c77d",
   "metadata": {},
   "source": [
    "Detach xarray object from any backing file - force data into RAM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3586c43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "INSAR_H5_ts = insar_m  \n",
    "W3RA_H5_ts  = BASE / \"w3ra_aligned.h5\"    # contains Sg, Sd, S0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d2d683e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# ---- model/data config ----\n",
    "WIN_T = 12             # months per training window (receptive field in time)\n",
    "PATCH = (1, 128, 128)  # (t,h,w) patch fed to model; t must equal WIN_T for this script\n",
    "STRIDE = (1, 128, 128) # sampling stride for patches\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 5\n",
    "LR = 2e-4\n",
    "DEVICE = \"cpu\"   # \"cuda\" if torch.cuda.is_available() else \"cpu\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "69639e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py, numpy as np, torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "'''\n",
    "USAGE: \n",
    "train_ds = InSAR2W3RA(INSAR_H5, W3RA_H5, win_t=WIN_T, patch_sz=PATCH, stride=STRIDE, split=\"train\")\n",
    "val_ds   = InSAR2W3RA(INSAR_H5, W3RA_H5, win_t=WIN_T, patch_sz=PATCH, stride=STRIDE, split=\"val\")\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,  num_workers=2, pin_memory=True)\n",
    "val_dl   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
    "len(train_ds), len(val_ds)\n",
    "'''\n",
    "\n",
    "class InSAR2W3RA(Dataset):\n",
    "    def __init__(self, insar_h5, w3ra_h5, win_t=12, patch_sz=(1,128,128), stride=(1,128,128),\n",
    "                 split=\"train\", val_frac=0.1, test_frac=0.1, zscore=True, seed=0):\n",
    "        self.f_in = h5py.File(insar_h5, \"r\")\n",
    "        self.f_w3 = h5py.File(w3ra_h5,  \"r\")\n",
    "        self.D_in = self.f_in[\"InSAR\"]        # (T,H,W)\n",
    "        self.D0 = self.f_w3[\"S0\"]             # (T,H,W)\n",
    "        self.Dd = self.f_w3[\"Sd\"]\n",
    "        self.Dg = self.f_w3[\"Sg\"]\n",
    "\n",
    "        T,H,W = self.D_in.shape\n",
    "        self.win_t = win_t\n",
    "        self.pz = patch_sz\n",
    "        self.stride = stride\n",
    "        assert patch_sz[0] in (1, win_t), \"Time patch must be 1 or WIN_T; use WIN_T here.\"\n",
    "        assert win_t <= T\n",
    "\n",
    "        # build list of (t0,y0,x0) windows\n",
    "        t_idx = np.arange(0, T - win_t + 1, stride[0])\n",
    "        y_idx = np.arange(0, H - patch_sz[1] + 1, stride[1])\n",
    "        x_idx = np.arange(0, W - patch_sz[2] + 1, stride[2])\n",
    "        idx = np.stack(np.meshgrid(t_idx, y_idx, x_idx, indexing=\"ij\"), -1).reshape(-1,3)\n",
    "\n",
    "        # split by time (keeps spatial leakage low)\n",
    "        n_t = len(t_idx)\n",
    "        n_val = max(1,int(n_t*val_frac))\n",
    "        n_test= max(1,int(n_t*test_frac))\n",
    "        rng = np.random.default_rng(seed)\n",
    "        # choose complete time starts for val/test\n",
    "        t_perm = rng.permutation(n_t)\n",
    "        t_val  = set(t_idx[t_perm[:n_val]])\n",
    "        t_test = set(t_idx[t_perm[n_val:n_val+n_test]])\n",
    "\n",
    "        if split==\"train\":\n",
    "            mask = np.array([t not in t_val and t not in t_test for t,_,_ in idx])\n",
    "        elif split==\"val\":\n",
    "            mask = np.array([t in t_val for t,_,_ in idx])\n",
    "        else:\n",
    "            mask = np.array([t in t_test for t,_,_ in idx])\n",
    "\n",
    "        self.samples = idx[mask]\n",
    "\n",
    "        # compute z-score statistics (approx: sample 200 patches)\n",
    "        self.zscore = zscore\n",
    "        if zscore:\n",
    "            self.x_mean, self.x_std, self.y_mean, self.y_std = self._estimate_stats(rng, nsamp=200)\n",
    "        else:\n",
    "            self.x_mean = self.x_std = self.y_mean = self.y_std = None\n",
    "\n",
    "    def _estimate_stats(self, rng, nsamp=200):\n",
    "        xs, ys = [], []\n",
    "        for _ in range(min(nsamp, len(self.samples))):\n",
    "            t,y,x = self.samples[rng.integers(len(self.samples))]\n",
    "            s = slice(t, t+self.win_t)\n",
    "            yy = slice(y, y+self.pz[1]); xx = slice(x, x+self.pz[2])\n",
    "            xin = self.D_in[s, yy, xx]       # (T,H,W)\n",
    "            yout = np.stack([self.D0[s, yy, xx],\n",
    "                             self.Dd[s, yy, xx],\n",
    "                             self.Dg[s, yy, xx]], axis=0)   # (3,T,H,W)\n",
    "            xs.append(np.nan_to_num(xin, nan=0.0))\n",
    "            ys.append(np.nan_to_num(yout, nan=0.0))\n",
    "        xcat = np.concatenate([u.reshape(-1,1) for u in xs],0)\n",
    "        ycat = np.concatenate([u.reshape(-1,1) for u in ys],0)\n",
    "        x_mean, x_std = float(np.mean(xcat)), float(np.std(xcat)+1e-6)\n",
    "        y_mean, y_std = float(np.mean(ycat)), float(np.std(ycat)+1e-6)\n",
    "        return x_mean, x_std, y_mean, y_std\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        t,y,x = self.samples[i]\n",
    "        s = slice(t, t+self.win_t)\n",
    "        yy = slice(y, y+self.pz[1]); xx = slice(x, x+self.pz[2])\n",
    "\n",
    "        xin  = self.D_in[s, yy, xx].astype(np.float32)         # (T,H,W)\n",
    "        yout = np.stack([ self.D0[s,yy,xx], self.Dd[s,yy,xx], self.Dg[s,yy,xx] ],\n",
    "                        axis=0).astype(np.float32)             # (3,T,H,W)\n",
    "\n",
    "        # masks for NaN\n",
    "        m = ~np.isnan(yout)                                    # (3,T,H,W)\n",
    "        xin  = np.nan_to_num(xin,  nan=0.0)\n",
    "        yout = np.nan_to_num(yout, nan=0.0)\n",
    "\n",
    "        if self.zscore:\n",
    "            xin  = (xin  - self.x_mean)/self.x_std\n",
    "            yout = (yout - self.y_mean)/self.y_std\n",
    "\n",
    "        x_t = torch.from_numpy(xin).unsqueeze(0)               # [1,T,H,W]\n",
    "        y_t = torch.from_numpy(yout)                           # [3,T,H,W]\n",
    "        m_t = torch.from_numpy(m.astype(np.float32))           # [3,T,H,W]\n",
    "        return x_t, y_t, m_t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75bcac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- S0 ---\n",
      "vars: ['Sg', 'Sd', 'S0']\n",
      "dims: {'lat': 22, 'lon': 24, 'time': 65}\n",
      "time: ['2017-06-01T00:00:00.000000000' '2017-07-01T00:00:00.000000000'\n",
      " '2017-08-01T00:00:00.000000000'] … ['2022-08-01T00:00:00.000000000' '2022-09-01T00:00:00.000000000'\n",
      " '2022-10-01T00:00:00.000000000'] (65 steps)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JR80FD\\AppData\\Local\\Temp\\ipykernel_16316\\2079874011.py:10: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(\"dims:\", dict(ds.dims))\n",
      "C:\\Users\\JR80FD\\AppData\\Local\\Temp\\ipykernel_16316\\2079874011.py:12: FutureWarning: The return type of `Dataset.dims` will be changed to return a set of dimension names in future, in order to be more consistent with `DataArray.dims`. To access a mapping from dimension names to lengths, please use `Dataset.sizes`.\n",
      "  print(\"time:\", str(ds.time.values[:3]), \"…\", str(ds.time.values[-3:]), f\"({ds.dims['time']} steps)\")\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "p = BASE / \"w3ra_aligned.nc\"\n",
    "try:\n",
    "    ds = xr.open_dataset(p)\n",
    "    print(\"\\n---\", name, \"---\")\n",
    "    print(\"vars:\", list(ds.data_vars)[:10])\n",
    "    print(\"dims:\", dict(ds.dims))\n",
    "    if \"time\" in ds:\n",
    "        print(\"time:\", str(ds.time.values[:3]), \"…\", str(ds.time.values[-3:]), f\"({ds.dims['time']} steps)\")\n",
    "    ds.close()\n",
    "except Exception as e:\n",
    "    print(\"\\n---\", name, \"---\\n\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "20866333",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Unable to synchronously open object (object 'S0' doesn't exist)\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[1;32m----> 4\u001b[0m train_ds \u001b[38;5;241m=\u001b[39m \u001b[43mInSAR2W3RA\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINSAR_H5_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mW3RA_H5_ts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwin_t\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mWIN_T\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatch_sz\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPATCH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTRIDE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      5\u001b[0m val_ds   \u001b[38;5;241m=\u001b[39m InSAR2W3RA(INSAR_H5_ts, W3RA_H5_ts, win_t\u001b[38;5;241m=\u001b[39mWIN_T, patch_sz\u001b[38;5;241m=\u001b[39mPATCH, stride\u001b[38;5;241m=\u001b[39mSTRIDE, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      8\u001b[0m train_dl \u001b[38;5;241m=\u001b[39m DataLoader(train_ds, batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE,\n\u001b[0;32m      9\u001b[0m                       shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, num_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,  \u001b[38;5;66;03m# <-- important\u001b[39;00m\n\u001b[0;32m     10\u001b[0m                       pin_memory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, persistent_workers\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[43], line 19\u001b[0m, in \u001b[0;36mInSAR2W3RA.__init__\u001b[1;34m(self, insar_h5, w3ra_h5, win_t, patch_sz, stride, split, val_frac, test_frac, zscore, seed)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_w3 \u001b[38;5;241m=\u001b[39m h5py\u001b[38;5;241m.\u001b[39mFile(w3ra_h5,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD_in \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_in[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInSAR\u001b[39m\u001b[38;5;124m\"\u001b[39m]        \u001b[38;5;66;03m# (T,H,W)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mD0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mf_w3\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mS0\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m             \u001b[38;5;66;03m# (T,H,W)\u001b[39;00m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_w3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSd\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_w3[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSg\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\JR80FD\\.conda\\envs\\datasci_env\\lib\\site-packages\\h5py\\_hl\\group.py:360\u001b[0m, in \u001b[0;36mGroup.__getitem__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid HDF5 object reference\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(name, (\u001b[38;5;28mbytes\u001b[39m, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[1;32m--> 360\u001b[0m     oid \u001b[38;5;241m=\u001b[39m \u001b[43mh5o\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_e\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_lapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    361\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    362\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccessing a group is done with bytes or str, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    363\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mtype\u001b[39m(name)))\n",
      "File \u001b[1;32mh5py/_objects.pyx:56\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/_objects.pyx:57\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py/h5o.pyx:257\u001b[0m, in \u001b[0;36mh5py.h5o.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Unable to synchronously open object (object 'S0' doesn't exist)\""
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "train_ds = InSAR2W3RA(INSAR_H5_ts, W3RA_H5_ts, win_t=WIN_T, patch_sz=PATCH, stride=STRIDE, split=\"train\")\n",
    "val_ds   = InSAR2W3RA(INSAR_H5_ts, W3RA_H5_ts, win_t=WIN_T, patch_sz=PATCH, stride=STRIDE, split=\"val\")\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE,\n",
    "                      shuffle=True, num_workers=0,  # <-- important\n",
    "                      pin_memory=False, persistent_workers=False)\n",
    "\n",
    "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE,\n",
    "                      shuffle=False, num_workers=0, # <-- important\n",
    "                      pin_memory=False, persistent_workers=False)\n",
    "\n",
    "\n",
    "\n",
    "len(train_ds), len(val_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "acdc376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def window_partition_3d(x, win):  # x: [B,T,H,W,C]\n",
    "    WT,WH,WW = win\n",
    "    B,T,H,W,C = x.shape\n",
    "    assert T%WT==0 and H%WH==0 and W%WW==0\n",
    "    x = x.view(B, T//WT, WT, H//WH, WH, W//WW, WW, C)\n",
    "    x = x.permute(0,1,3,5,2,4,6,7).contiguous()               # [B, nWT, nWH, nWW, WT, WH, WW, C]\n",
    "    return x.view(-1, WT*WH*WW, C)                            # [B*nWins, tokens, C]\n",
    "\n",
    "def window_unpartition_3d(windows, win, B, T, H, W, C):\n",
    "    WT,WH,WW = win\n",
    "    nWT, nWH, nWW = T//WT, H//WH, W//WW\n",
    "    x = windows.view(B, nWT, nWH, nWW, WT, WH, WW, C)\n",
    "    x = x.permute(0,1,4,2,5,3,6,7).contiguous()\n",
    "    return x.view(B, T, H, W, C)\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim*mlp_ratio)\n",
    "        self.act = nn.GELU()\n",
    "        self.fc2 = nn.Linear(dim*mlp_ratio, dim)\n",
    "    def forward(self, x): return self.fc2(self.act(self.fc1(x)))\n",
    "\n",
    "class SwinBlock3D(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, window_size=(2,4,4), shift=False):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.win = window_size\n",
    "        self.shift = shift\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn  = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        self.mlp   = MLP(dim)\n",
    "\n",
    "    def forward(self, x):               # x: [B,T,H,W,C]\n",
    "        B,T,H,W,C = x.shape\n",
    "        if self.shift:\n",
    "            sT,sH,sW = self.win[0]//2, self.win[1]//2, self.win[2]//2\n",
    "            x = torch.roll(x, shifts=(-sT,-sH,-sW), dims=(1,2,3))\n",
    "        # partition → attn per window\n",
    "        xw = window_partition_3d(x, self.win)               # [B*nWins, tokens, C]\n",
    "        xw = self.norm1(xw)\n",
    "        attn_out,_ = self.attn(xw, xw, xw)                  # window MSA\n",
    "        xw = xw + attn_out\n",
    "        xw = xw + self.mlp(self.norm2(xw))\n",
    "        # unpartition\n",
    "        x = window_unpartition_3d(xw, self.win, B,T,H,W,C)\n",
    "        if self.shift:\n",
    "            sT,sH,sW = self.win[0]//2, self.win[1]//2, self.win[2]//2\n",
    "            x = torch.roll(x, shifts=(+sT,+sH,+sW), dims=(1,2,3))\n",
    "        return x\n",
    "\n",
    "class PatchEmbed3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, embed_dim=96, patch_size=(1,4,4)):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv3d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "    def forward(self, x):               # [B,1,T,H,W]\n",
    "        x = self.proj(x)                # [B,C,T',H',W']\n",
    "        x = x.permute(0,2,3,4,1)        # → [B,T',H',W',C]\n",
    "        return x\n",
    "\n",
    "class PatchMerge3D(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.reduction = nn.Linear(dim*4, dim*2)\n",
    "    def forward(self, x):               # [B,T,H,W,C]\n",
    "        B,T,H,W,C = x.shape\n",
    "        x = x.view(B,T, H//2,2, W//2,2, C).permute(0,1,2,4,3,5,6).contiguous()\n",
    "        x = x.view(B,T, H//2, W//2, 4*C)\n",
    "        return self.reduction(x)\n",
    "\n",
    "class PatchExpand3D(nn.Module):\n",
    "    def __init__(self, dim_out):\n",
    "        super().__init__()\n",
    "        self.dim_out = dim_out\n",
    "    def forward(self, x):               # [B,T,H,W,Cin] → upsample H,W x2, reduce channels\n",
    "        B,T,H,W,C = x.shape\n",
    "        x = x.permute(0,4,1,2,3)        # [B,C,T,H,W]\n",
    "        x = F.interpolate(x, scale_factor=(1,2,2), mode=\"trilinear\", align_corners=False)\n",
    "        x = nn.Conv3d(C, self.dim_out, kernel_size=1)(x)\n",
    "        return x.permute(0,2,3,4,1)     # [B,T,H',W',Cout]\n",
    "\n",
    "class SwinUNet3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=3, embed_dim=96,\n",
    "                 depths=(2,2,2), num_heads=(3,3,3),\n",
    "                 window_size=(2,4,4), patch_size=(1,4,4)):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbed3D(in_ch, embed_dim, patch_size)\n",
    "        C = embed_dim\n",
    "\n",
    "        # encoder stages\n",
    "        self.enc1 = nn.ModuleList([SwinBlock3D(C,   num_heads[0], window_size, shift=(i%2==1)) for i in range(depths[0])])\n",
    "        self.pm1  = PatchMerge3D(C);   C *= 2\n",
    "        self.enc2 = nn.ModuleList([SwinBlock3D(C,   num_heads[1], window_size, shift=(i%2==1)) for i in range(depths[1])])\n",
    "        self.pm2  = PatchMerge3D(C);   C *= 2\n",
    "        self.enc3 = nn.ModuleList([SwinBlock3D(C,   num_heads[2], window_size, shift=(i%2==1)) for i in range(depths[2])])\n",
    "\n",
    "        # decoder\n",
    "        self.up2  = PatchExpand3D(C//2) # to match skip2\n",
    "        self.dec2 = nn.ModuleList([SwinBlock3D(C,   num_heads[1], window_size, shift=(i%2==1)) for i in range(1)])\n",
    "        self.up1  = PatchExpand3D(C//4) # to match skip1\n",
    "        self.dec1 = nn.ModuleList([SwinBlock3D(C//2,num_heads[0], window_size, shift=(i%2==1)) for i in range(1)])\n",
    "\n",
    "        self.head = nn.Sequential(\n",
    "            nn.LayerNorm(C//2),\n",
    "            nn.Linear(C//2, out_ch)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):               # x: [B,1,T,H,W]\n",
    "        B = x.size(0)\n",
    "        z = self.patch_embed(x)         # [B,T',H',W',C]\n",
    "        # enc1\n",
    "        for blk in self.enc1: z = blk(z)\n",
    "        skip1 = z\n",
    "        z = self.pm1(z)                 # down x2 (H,W), Cx2\n",
    "        # enc2\n",
    "        for blk in self.enc2: z = blk(z)\n",
    "        skip2 = z\n",
    "        z = self.pm2(z)                 # down x2 again\n",
    "        # enc3 (bottleneck)\n",
    "        for blk in self.enc3: z = blk(z)\n",
    "        # up2\n",
    "        z = self.up2(z)                 # up x2\n",
    "        z = torch.cat([z, skip2], dim=-1)\n",
    "        for blk in self.dec2: z = blk(z)\n",
    "        # up1\n",
    "        z = self.up1(z)                 # up x2\n",
    "        z = torch.cat([z, skip1], dim=-1)\n",
    "        for blk in self.dec1: z = blk(z)\n",
    "        # head linear per-token → channels\n",
    "        B,T,H,W,C = z.shape\n",
    "        z = self.head(z).view(B,T,H,W,-1).permute(0,4,1,2,3)  # [B,out_ch,T,H,W]\n",
    "        return z\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1d2d123e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskedMAE(nn.Module):\n",
    "    def __init__(self): super().__init__()\n",
    "    def forward(self, pred, tgt, mask):\n",
    "        # pred,tgt: [B,3,T,H,W]; mask: [B,3,T,H,W] (1=valid)\n",
    "        valid = mask>0.5\n",
    "        diff = torch.abs(pred - tgt)\n",
    "        diff = diff[valid]\n",
    "        return diff.mean() if diff.numel() else (pred-tgt).abs().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f6139876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = \"cpu\"   # force CPU\n",
    "print(\"Using\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee81aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (128) at non-singleton dimension 4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tot\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m1\u001b[39m,n)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, NUM_EPOCHS\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m---> 27\u001b[0m     tr \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     28\u001b[0m     va \u001b[38;5;241m=\u001b[39m step(val_dl,   \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m02d\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | train \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtr\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | val \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mva\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[54], line 17\u001b[0m, in \u001b[0;36mstep\u001b[1;34m(dl, train)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train: opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     16\u001b[0m yhat \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m---> 17\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43myhat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m train:\n\u001b[0;32m     19\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\JR80FD\\.conda\\envs\\datasci_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\JR80FD\\.conda\\envs\\datasci_env\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[47], line 6\u001b[0m, in \u001b[0;36mMaskedMAE.forward\u001b[1;34m(self, pred, tgt, mask)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, pred, tgt, mask):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# pred,tgt: [B,3,T,H,W]; mask: [B,3,T,H,W] (1=valid)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m     valid \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m0.5\u001b[39m\n\u001b[1;32m----> 6\u001b[0m     diff \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mabs(\u001b[43mpred\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtgt\u001b[49m)\n\u001b[0;32m      7\u001b[0m     diff \u001b[38;5;241m=\u001b[39m diff[valid]\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m diff\u001b[38;5;241m.\u001b[39mmean() \u001b[38;5;28;01mif\u001b[39;00m diff\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;28;01melse\u001b[39;00m (pred\u001b[38;5;241m-\u001b[39mtgt)\u001b[38;5;241m.\u001b[39mabs()\u001b[38;5;241m.\u001b[39mmean()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (128) at non-singleton dimension 4"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "model = SwinUNet3D(in_ch=1, out_ch=3, embed_dim=64,\n",
    "                   depths=(2,2,2), num_heads=(2,4,4),\n",
    "                   window_size=(2,4,4), patch_size=(1,4,4)).to(DEVICE)\n",
    "\n",
    "opt  = torch.optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-2)\n",
    "loss_fn = MaskedMAE()\n",
    "\n",
    "def step(dl, train=True):\n",
    "    model.train(train)\n",
    "    tot, n = 0.0, 0\n",
    "    for x,y,m in dl:\n",
    "        x = x.to(DEVICE)                 # [B,1,T,H,W]\n",
    "        y = y.to(DEVICE)                 # [B,3,T,H,W]\n",
    "        m = m.to(DEVICE)                 # [B,3,T,H,W]\n",
    "        if train: opt.zero_grad()\n",
    "        yhat = model(x)\n",
    "        loss = loss_fn(yhat, y, m)\n",
    "        if train:\n",
    "            loss.backward()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "            opt.step()\n",
    "        tot += float(loss.detach().cpu())\n",
    "        n += 1\n",
    "    return tot/max(1,n)\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS+1):\n",
    "    tr = step(train_dl, True)\n",
    "    va = step(val_dl,   False)\n",
    "    print(f\"Epoch {epoch:02d} | train {tr:.4f} | val {va:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078816af",
   "metadata": {},
   "source": [
    "# 6) Build model tensors [B, C, T, H, W]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c1760e",
   "metadata": {},
   "source": [
    "Input \n",
    "X: InSAR → [B, 1, T, H, W]\n",
    "\n",
    "Output \n",
    "Y: stack W3RA layers → [B, 3, T, H, W]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "892a0506",
   "metadata": {},
   "source": [
    "We’ll also normalize (z-score) and keep the stats for de-normalization later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55fd2f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack W3RA channels in the order [Sg, Sd, S0]\n",
    "w3ra_stack = xr.concat([sg_r, sd_r, s0_r], dim=\"channel\").assign_coords(channel=[\"Sg\",\"Sd\",\"S0\"])\n",
    "print(\"W3RA stack:\", w3ra_stack.shape, w3ra_stack.coords[\"channel\"].values)\n",
    "\n",
    "# Ensure matching dims order: (time, y, x)\n",
    "insar_m = insar_m.transpose(\"time\",\"y\",\"x\")\n",
    "w3ra_stack = w3ra_stack.transpose(\"time\",\"y\",\"x\")\n",
    "\n",
    "T, H, W = insar_m.shape\n",
    "C_out = 3\n",
    "\n",
    "# to numpy\n",
    "x_np = insar_m.values.astype(np.float32)                     # (T,H,W)\n",
    "y_np = w3ra_stack.values.astype(np.float32)                  # (C_out,T,H,W)\n",
    "\n",
    "# add batch and channel dimensions → [B, C, T, H, W]\n",
    "x_t = torch.from_numpy(x_np).unsqueeze(0).unsqueeze(1)       # [1,1,T,H,W]\n",
    "y_t = torch.from_numpy(y_np).unsqueeze(0)                    # [1,C_out,T,H,W]\n",
    "\n",
    "print(\"X tensor:\", x_t.shape, \" Y tensor:\", y_t.shape)\n",
    "\n",
    "# ---- Normalization ----\n",
    "# InSAR: single channel\n",
    "x_mean = x_t.mean(); x_std = x_t.std().clamp_min(1e-6)\n",
    "x_norm = (x_t - x_mean) / x_std\n",
    "\n",
    "# W3RA per-channel stats\n",
    "y_mean = y_t.mean(dim=(0,2,3,4), keepdim=True)\n",
    "y_std  = y_t.std(dim=(0,2,3,4), keepdim=True).clamp_min(1e-6)\n",
    "y_norm = (y_t - y_mean) / y_std\n",
    "\n",
    "norm_stats = {\"x_mean\": float(x_mean), \"x_std\": float(x_std),\n",
    "              \"y_mean\": y_mean.squeeze().tolist(), \"y_std\": y_std.squeeze().tolist()}\n",
    "norm_stats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2851fbf2",
   "metadata": {},
   "source": [
    "# 7) Minimal model (the “modified” Swin-lite U-Net)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9ec398",
   "metadata": {},
   "source": [
    "Paste this once if you don’t already have it in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4071c5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSwinBlock3D(nn.Module):\n",
    "    def __init__(self, dim, num_heads=4, mlp_ratio=4.0):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=num_heads, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(dim)\n",
    "        hidden = int(dim * mlp_ratio)\n",
    "        self.mlp = nn.Sequential(nn.Linear(dim, hidden), nn.GELU(), nn.Linear(hidden, dim))\n",
    "\n",
    "    def forward(self, x):  # [B,C,T,H,W]\n",
    "        B, C, T, H, W = x.shape\n",
    "        y = x.permute(0,2,3,4,1).contiguous().view(B, T*H*W, C)\n",
    "        z = self.norm1(y)\n",
    "        out,_ = self.attn(z,z,z)\n",
    "        y = y + out\n",
    "        y = y + self.mlp(self.norm2(y))\n",
    "        return y.view(B,T,H,W,C).permute(0,4,1,2,3).contiguous()\n",
    "\n",
    "class PatchEmbed3D(nn.Module):\n",
    "    def __init__(self, in_ch=1, embed_dim=64, patch_size=(1,4,4)):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv3d(in_ch, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "        self.bn = nn.BatchNorm3d(embed_dim)\n",
    "    def forward(self, x):\n",
    "        return self.bn(self.proj(x))\n",
    "\n",
    "class Swin3DNetMini(nn.Module):\n",
    "    def __init__(self, in_ch=1, out_ch=3, embed_dim=64):\n",
    "        super().__init__()\n",
    "        self.patch = PatchEmbed3D(in_ch, embed_dim, patch_size=(1,4,4))\n",
    "        self.enc1  = SimpleSwinBlock3D(embed_dim, num_heads=4)\n",
    "        self.down  = nn.Conv3d(embed_dim, embed_dim*2, kernel_size=(1,2,2), stride=(1,2,2))\n",
    "        self.enc2  = SimpleSwinBlock3D(embed_dim*2, num_heads=8)\n",
    "        self.up    = nn.ConvTranspose3d(embed_dim*2, embed_dim, kernel_size=(1,2,2), stride=(1,2,2))\n",
    "        self.fuse  = nn.Conv3d(embed_dim*2, embed_dim, kernel_size=1)\n",
    "        self.head  = nn.Conv3d(embed_dim, out_ch, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):  # [B,1,T,H,W]\n",
    "        B,_,T,H,W = x.shape\n",
    "        z0 = self.patch(x)           # [B,D,T,H/4,W/4]\n",
    "        e1 = self.enc1(z0)\n",
    "        e2i= self.down(e1)           # [B,2D,T,H/8,W/8]\n",
    "        e2 = self.enc2(e2i)\n",
    "        up = self.up(e2)             # [B,D,T,H/4,W/4]\n",
    "        cat= torch.cat([up, e1], dim=1)\n",
    "        fz = self.fuse(cat)\n",
    "        y  = self.head(fz)           # [B,out_ch,T,H/4,W/4]\n",
    "        # back to original size\n",
    "        y  = F.interpolate(y, size=(T,H,W), mode=\"trilinear\", align_corners=False)\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f84a7ef",
   "metadata": {},
   "source": [
    "# 8) Train for a few epochs (sanity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ebf9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Swin3DNetMini(in_ch=1, out_ch=3, embed_dim=64).to(device)\n",
    "\n",
    "x_batch = x_norm.to(device)  # [1,1,T,H,W]\n",
    "y_batch = y_norm.to(device)  # [1,3,T,H,W]\n",
    "\n",
    "criterion = nn.L1Loss()  # MAE (you can switch to MSE)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
    "\n",
    "loss_history = []\n",
    "model.train()\n",
    "for epoch in range(10):   # start small to test pipeline\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(x_batch)\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    loss_history.append(loss.item())\n",
    "    print(f\"epoch {epoch+1:02d} | loss {loss.item():.5f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6117dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(loss_history); plt.xlabel(\"epoch\"); plt.ylabel(\"train loss\"); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7bc989",
   "metadata": {},
   "source": [
    "# 9) De-normalize and inspect one pixel time series + lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e21072",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    y_hat = model(x_batch).cpu()    # [1,3,T,H,W]\n",
    "\n",
    "# de-normalize\n",
    "y_hat_dn = y_hat * y_std + y_mean   # back to original units\n",
    "\n",
    "# center pixel\n",
    "_, C, T, H, W = y_hat.shape\n",
    "i, j = H//2, W//2\n",
    "names = [\"Sg\",\"Sd\",\"S0\"]\n",
    "\n",
    "def best_lag(yt, yp, max_lag=6):\n",
    "    lags = np.arange(-max_lag, max_lag+1)\n",
    "    corrs = []\n",
    "    for L in lags:\n",
    "        if L>0: a,b = yt[L:], yp[:-L]\n",
    "        elif L<0: a,b = yt[:L], yp[-L:]\n",
    "        else: a,b = yt, yp\n",
    "        if len(a)>=2 and len(b)>=2:\n",
    "            corrs.append(np.corrcoef(a,b)[0,1])\n",
    "        else:\n",
    "            corrs.append(np.nan)\n",
    "    k = int(np.nanargmax(corrs))\n",
    "    return int(lags[k]), float(corrs[k])\n",
    "\n",
    "for c,name in enumerate(names):\n",
    "    yt = (y_t[0,c,:,i,j]*y_std[0,c,0,0,0] + y_mean[0,c,0,0,0]).cpu().numpy()\n",
    "    yp = y_hat_dn[0,c,:,i,j].numpy()\n",
    "    L, R = best_lag(yt, yp, max_lag=6)\n",
    "    print(f\"{name}: best lag={L} steps, corr={R:.3f}\")\n",
    "    plt.figure(); plt.plot(yt,label=\"true\"); plt.plot(yp,label=\"pred\")\n",
    "    plt.title(f\"{name} @ center pixel (lag {L}, corr {R:.2f})\"); plt.legend(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdda46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42a6840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfd13f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "ds = xr.open_dataset(r\"C:\\Users\\jr80fd\\swin_test\\w3ra\\Sg_EU.nc\")  # works once netCDF4 is present\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127b17f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      4\u001b[0m nc_paths \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m      5\u001b[0m     Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjr80fd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mswin_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw3ra\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW3RA_Sg_EU.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      6\u001b[0m     Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjr80fd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mswin_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw3ra\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mW3RA_Sd_EU.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      7\u001b[0m     Path(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mjr80fd\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mswin_test\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw3ra\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mS0_EU.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m      8\u001b[0m ]\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m nc_paths:\n\u001b[1;32m---> 11\u001b[0m     ds \u001b[38;5;241m=\u001b[39m \u001b[43mxr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, p\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28mprint\u001b[39m(ds)            \u001b[38;5;66;03m# prints dims/coords/vars\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\JR80FD\\.conda\\envs\\datasci_env\\lib\\site-packages\\xarray\\backends\\api.py:668\u001b[0m, in \u001b[0;36mopen_dataset\u001b[1;34m(filename_or_obj, engine, chunks, cache, decode_cf, mask_and_scale, decode_times, decode_timedelta, use_cftime, concat_characters, decode_coords, drop_variables, inline_array, chunked_array_type, from_array_kwargs, backend_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m    665\u001b[0m     kwargs\u001b[38;5;241m.\u001b[39mupdate(backend_kwargs)\n\u001b[0;32m    667\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 668\u001b[0m     engine \u001b[38;5;241m=\u001b[39m \u001b[43mplugins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mguess_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    670\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_array_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    671\u001b[0m     from_array_kwargs \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\JR80FD\\.conda\\envs\\datasci_env\\lib\\site-packages\\xarray\\backends\\plugins.py:194\u001b[0m, in \u001b[0;36mguess_engine\u001b[1;34m(store_spec)\u001b[0m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     error_msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    188\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound the following matches with the input file in xarray\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms IO \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    189\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackends: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcompatible_engines\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. But their dependencies may not be installed, see:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    190\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/user-guide/io.html \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    191\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    192\u001b[0m     )\n\u001b[1;32m--> 194\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(error_msg)\n",
      "\u001b[1;31mValueError\u001b[0m: found the following matches with the input file in xarray's IO backends: ['netcdf4', 'h5netcdf']. But their dependencies may not be installed, see:\nhttps://docs.xarray.dev/en/stable/user-guide/io.html \nhttps://docs.xarray.dev/en/stable/getting-started-guide/installing.html"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "\n",
    "nc_paths = [\n",
    "    Path(r\"C:\\Users\\jr80fd\\swin_test\\w3ra\\W3RA_Sg_EU.nc\"),\n",
    "    Path(r\"C:\\Users\\jr80fd\\swin_test\\w3ra\\W3RA_Sd_EU.nc\"),\n",
    "    Path(r\"C:\\Users\\jr80fd\\swin_test\\w3ra\\S0_EU.nc\"),\n",
    "]\n",
    "\n",
    "for p in nc_paths:\n",
    "    ds = xr.open_dataset(p)\n",
    "    print(\"\\n\", p.name)\n",
    "    print(ds)            # prints dims/coords/vars\n",
    "    print(\"vars:\", list(ds.data_vars))\n",
    "    for v in ds.data_vars:\n",
    "        print(v, ds[v].dims, ds[v].shape, ds[v].attrs)\n",
    "    ds.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swin_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
